# Projeto 1: Classifica√ß√£o de Doen√ßas Card√≠acas# Projeto 1: Classifica√ß√£o de Doen√ßas Card√≠acas# Projeto 1: Classifica√ß√£o de Doen√ßas Card√≠acas - Fundamentos de IA# Projeto 1: Classifica√ß√£o de Doen√ßas Card√≠acas - Fundamentos de IA

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)

[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://www.tensorflow.org/)

[![Keras](https://img.shields.io/badge/Keras-API-red.svg)](https://keras.io/)[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://www.tensorflow.org/)

[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3+-yellow.svg)](https://scikit-learn.org/)

[![Keras](https://img.shields.io/badge/Keras-API-red.svg)](https://keras.io/)[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://www.tensorflow.org/)[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://www.tensorflow.org/)

> **Disciplina:** Fundamentos de Intelig√™ncia Artificial (FIA)

> **Autores:** Alexandre Pereira de Souza Junior, Leonardo Brand√£o, Vithor Vit√≥rio [![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3+-yellow.svg)](https://scikit-learn.org/)

> **Institui√ß√£o:** Universidade Federal de Alagoas (UFAL)

[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)[![Keras](https://img.shields.io/badge/Keras-API-red.svg)](https://keras.io/)[![Keras](https://img.shields.io/badge/Keras-API-red.svg)](https://keras.io/)

---

> **Disciplina:** Fundamentos de Intelig√™ncia Artificial (FIA) [![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3+-yellow.svg)](https://scikit-learn.org/)[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3+-yellow.svg)](https://scikit-learn.org/)

## üìã Sum√°rio

> **Autores:** Alexandre Pereira de Souza Junior, Leonardo Brand√£o, Vithor Vit√≥rio

- [Descri√ß√£o do Projeto](#-descri√ß√£o-do-projeto)

- [An√°lise do Dataset](#-an√°lise-do-dataset)> **Institui√ß√£o:** Universidade Federal de Alagoas (UFAL)[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

- [Metodologia](#-metodologia)

- [Resultados Obtidos](#-resultados-obtidos)---> **Disciplina:** Fundamentos de Intelig√™ncia Artificial (FIA) > **Disciplina:** Fundamentos de Intelig√™ncia Artificial (FIA)

- [Conclus√µes](#-conclus√µes)

- [Como Executar](#-como-executar)## üìã Sum√°rio> **Autor:** Alexandre Pereira de Souza Junior, Leonardo Brand√£o, Vithor Vitorio. > **Autor:** Alexandre Pereira de Souza Junior, Leonardo Brand√£o, Vithor Vitorio.

- [Tecnologias Utilizadas](#-tecnologias-utilizadas)

- [Contexto e Objetivo](#-contexto-e-objetivo)---

---

- [An√°lise do Dataset](#-an√°lise-do-dataset)

## üìñ Descri√ß√£o do Projeto

- [Metodologia](#-metodologia)## üìã √çndice## üìã √çndice

### Contexto

- [Resultados](#-resultados)

As **doen√ßas cardiovasculares** s√£o a principal causa de morte em todo o mundo, tornando a detec√ß√£o precoce fundamental para salvar vidas. Este projeto aplica t√©cnicas de **Deep Learning** para auxiliar na identifica√ß√£o de pacientes com risco de doen√ßa card√≠aca.

- [Conclus√µes](#-conclus√µes)- [Contexto do Problema](#-contexto-do-problema)- [Contexto do Problema](#-contexto-do-problema)

### Objetivo

- [Como Executar](#-como-executar)

Desenvolver um **classificador bin√°rio** utilizando Redes Neurais Artificiais (ANN) para prever a **presen√ßa (1)** ou **aus√™ncia (0)** de doen√ßa card√≠aca em pacientes, com base em 13 atributos cl√≠nicos.

- [Tecnologias Utilizadas](#Ô∏è-tecnologias-utilizadas)- [Dataset: Origem, Estrutura e Limpeza](#-dataset-origem-estrutura-e-limpeza)- [Dataset: Origem, Estrutura e Limpeza](#-dataset-origem-estrutura-e-limpeza)

### Especifica√ß√µes T√©cnicas

- [Refer√™ncias](#-refer√™ncias)

- **Tipo:** Classifica√ß√£o Bin√°ria Supervisionada

- **Modelo:** Rede Neural Feedforward com 2 camadas ocultas- [Metodologia](#Ô∏è-metodologia)- [Metodologia](#Ô∏è-metodologia)

- **Ativa√ß√µes:** ReLU (camadas ocultas), Sigmoid (sa√≠da)

- **Regulariza√ß√£o:** Dropout (25%) + L2 (0.001)---

- **M√©tricas:** Acur√°cia, Precis√£o, Recall e Matriz de Confus√£o

- [Resultados e An√°lise Cr√≠tica](#-resultados-e-an√°lise-cr√≠tica)- [Resultados e An√°lise Cr√≠tica](#-resultados-e-an√°lise-cr√≠tica)

---

## üéØ Contexto e Objetivo

## üìä An√°lise do Dataset

- [Conclus√£o](#-conclus√£o)- [Conclus√£o](#-conclus√£o)

### Fonte de Dados

As **doen√ßas cardiovasculares** s√£o a principal causa de morte em todo o mundo, tornando a detec√ß√£o precoce um desafio cr√≠tico para a sa√∫de p√∫blica. A identifica√ß√£o precoce de pacientes em risco pode salvar vidas atrav√©s de interven√ß√µes preventivas e tratamentos adequados.

**Dataset:** Heart Disease UCI (Cleveland Heart Disease Database)

**Reposit√≥rio:** UCI Machine Learning Repository - [Instru√ß√µes de Execu√ß√£o](#-instru√ß√µes-de-execu√ß√£o)- [Instru√ß√µes de Execu√ß√£o](#-instru√ß√µes-de-execu√ß√£o)

**URL:** http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data

### Objetivo do Projeto

### Caracter√≠sticas

- [Refer√™ncias](#-refer√™ncias)- [Refer√™ncias](#-refer√™ncias)

- **Total de Amostras:** 303 pacientes

- **Amostras V√°lidas:** 297 (ap√≥s limpeza de 6 linhas com valores nulos)Desenvolver um **modelo de classifica√ß√£o bin√°ria** baseado em Redes Neurais Artificiais (ANN) capaz de prever a **presen√ßa (1)** ou **aus√™ncia (0)** de doen√ßa card√≠aca em um paciente, utilizando 13 atributos cl√≠nicos como entrada.

- **Features:** 13 atributos cl√≠nicos

- **Target:** Bin√°rio (0=saud√°vel, 1=doente)---

- **Divis√£o:** 80% treino (237 amostras) | 20% teste (60 amostras)

### Especifica√ß√µes T√©cnicas

### Atributos Cl√≠nicos

## üìã Contexto do Problema## üìã Contexto do Problema

| Feature | Descri√ß√£o |

|------------|------------------------------------------------|- **Tipo de Problema:** Classifica√ß√£o Bin√°ria Supervisionada

| `age` | Idade do paciente |

| `sex` | Sexo (1=masculino, 0=feminino) |- **Modelo:** Rede Neural Feedforward (2-3 camadas ocultas)Este projeto acad√™mico foi desenvolvido como parte da disciplina de Fundamentos de Intelig√™ncia Artificial e tem como objetivo construir um **classificador bin√°rio** para predi√ß√£o de doen√ßas card√≠acas. O modelo desenvolvido classifica pacientes em duas categorias:Este projeto acad√™mico foi desenvolvido como parte da disciplina de Fundamentos de Intelig√™ncia Artificial e tem como objetivo construir um **classificador bin√°rio** para predi√ß√£o de doen√ßas card√≠acas. O modelo desenvolvido classifica pacientes em duas categorias:

| `cp` | Tipo de dor no peito (0-3) |

| `trestbps` | Press√£o arterial em repouso (mm Hg) |- **Ativa√ß√£o:** ReLU nas camadas ocultas, Sigmoid na sa√≠da

| `chol` | Colesterol s√©rico (mg/dl) |

| `fbs` | Glicemia em jejum > 120 mg/dl |- **Regulariza√ß√£o:** Dropout para preven√ß√£o de overfitting- **0 (Saud√°vel)**: Aus√™ncia de doen√ßa card√≠aca- **0:** Aus√™ncia de doen√ßa card√≠aca (Saud√°vel)

| `restecg` | Resultados eletrocardiogr√°ficos |

| `thalach` | Frequ√™ncia card√≠aca m√°xima alcan√ßada |- **M√©tricas de Avalia√ß√£o:** Acur√°cia, Precis√£o, Recall e Matriz de Confus√£o

| `exang` | Angina induzida por exerc√≠cio |

| `oldpeak` | Depress√£o de ST induzida por exerc√≠cio |- **1 (Doente)**: Presen√ßa de doen√ßa card√≠aca- **1:** Presen√ßa de doen√ßa card√≠aca (Doente)

| `slope` | Inclina√ß√£o do segmento ST |

| `ca` | N√∫mero de vasos principais (0-3) |---

| `thal` | Talassemia (defeito card√≠aco) |

A abordagem utiliza t√©cnicas de **Deep Learning** para analisar 13 atributos cl√≠nicos e fisiol√≥gicos de pacientes, construindo uma Rede Neural Artificial (ANN) feedforward capaz de realizar predi√ß√µes com base em dados hist√≥ricos.---

### Pr√©-processamento

## üìä An√°lise do Dataset

1. **Limpeza:** Remo√ß√£o de 6 linhas com valores nulos (303 ‚Üí 297 amostras)

2. **Transforma√ß√£o:** Convers√£o do target multi-classe (0-4) para bin√°rio (0-1)---## üõ†Ô∏è Metodologia

3. **Divis√£o Estratificada:** 80/20 com manuten√ß√£o da propor√ß√£o de classes

4. **Normaliza√ß√£o:** StandardScaler aplicado ap√≥s divis√£o treino/teste### Fonte de Dados

---## üî¨ Dataset: Origem, Estrutura e LimpezaO projeto foi estruturado em **cinco fases principais**, seguindo um pipeline rigoroso de Data Science para garantir a validade e a replicabilidade dos resultados.

## üß† Metodologia**Dataset:** Heart Disease UCI (Cleveland Heart Disease Database)

### Arquitetura da Rede Neural**Reposit√≥rio:** UCI Machine Learning Repository ### Fonte de Dados### Fase 1Ô∏è‚É£: An√°lise Explorat√≥ria de Dados (EDA)

`````**URL Original:** http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data

Input Layer (13 features)

    ‚Üì**Dispon√≠vel tamb√©m em:** [Kaggle - Heart Disease Dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)O dataset utilizado √© o cl√°ssico **Cleveland Heart Disease Database** do reposit√≥rio UCI Machine Learning, acess√≠vel via:Antes de qualquer modelagem, uma an√°lise detalhada foi conduzida para entender a natureza dos dados:

Dense(16 neur√¥nios) + ReLU + L2(0.001) + Dropout(25%)

    ‚Üì### Caracter√≠sticas do Dataset````- **Balanceamento de Classes**: Verifica√ß√£o da distribui√ß√£o entre pacientes saud√°veis e doentes

Dense(8 neur√¥nios) + ReLU + L2(0.001) + Dropout(25%)

    ‚Üì- **Amostras Totais:** 303 pacienteshttp://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data- **Matriz de Correla√ß√£o**: Identifica√ß√£o de rela√ß√µes lineares entre as features

Output(1 neur√¥nio) + Sigmoid ‚Üí Probabilidade [0, 1]

```- **Amostras Utilizadas:** 297 (ap√≥s limpeza de valores nulos)



### Configura√ß√£o de Treinamento- **Atributos:** 13 features cl√≠nicas + 1 vari√°vel target```- **Estat√≠sticas Descritivas**: Compreens√£o da distribui√ß√£o de cada atributo cl√≠nico



| Par√¢metro          | Valor                      |- **Divis√£o:** 80% treino (237 amostras) | 20% teste (60 amostras)

|--------------------|----------------------------|

| **Optimizer**      | Adam                       |### Atributos Cl√≠nicos (Features)

| **Loss Function**  | Binary Crossentropy        |

| **Epochs**         | 100                        |**Nota Importante sobre a Escolha do Dataset**: Durante a fase inicial do projeto, identificamos uma discrep√¢ncia entre o dataset sugerido no material de apoio (Kaggle, 1025 amostras) e o dataset utilizado no notebook de refer√™ncia do professor. Ap√≥s an√°lise cr√≠tica, confirmamos que o dataset correto para este projeto √© o **UCI Cleveland original (303 amostras)**, que representa o benchmark hist√≥rico para pesquisas em classifica√ß√£o de doen√ßas card√≠acas.### Fase 2Ô∏è‚É£: Pr√©-processamento e Preven√ß√£o de Data Leakage

| **Batch Size**     | 10                         |

| **Regularization** | L2 (0.001) + Dropout (25%) || Feature | Descri√ß√£o | Escala |



### Import√¢ncia da Normaliza√ß√£o|------------|------------------------------------------------|-------------|



A normaliza√ß√£o dos dados √© **cr√≠tica** para o sucesso de Redes Neurais:| `age` | Idade do paciente | 29-77 |



**Por que normalizar?**| `sex` | Sexo (1=masculino, 0=feminino) | 0-1 |### Estrutura do DatasetEsta foi a etapa t√©cnica **mais cr√≠tica** do projeto, onde seguimos rigorosamente as melhores pr√°ticas de Machine Learning.

- Features possuem escalas muito diferentes (ex: `chol`: 126-564 vs `sex`: 0-1)

- Sem normaliza√ß√£o, atributos de maior magnitude dominam o gradiente| `cp` | Tipo de dor no peito (0-3) | 0-3 |

- Dados normalizados permitem converg√™ncia mais r√°pida e est√°vel

| `trestbps` | Press√£o arterial em repouso (mm Hg) | ~94-200 |

**Preven√ß√£o de Data Leakage:**

- **Ordem CORRETA:** Dividir dados ‚Üí Fit no treino ‚Üí Transform em treino e teste| `chol` | Colesterol s√©rico (mg/dl) | ~126-564 |

- **Ordem ERRADA:** Normalizar tudo ‚Üí Dividir (causa vazamento de informa√ß√£o do teste)

| `fbs` | Glicemia em jejum > 120 mg/dl (1=sim, 0=n√£o) | 0-1 |- **Amostras Originais**: 303 pacientes#### Pipeline de Pr√©-processamento

```python

# ‚úÖ CORRETO| `restecg` | Resultados eletrocardiogr√°ficos em repouso | 0-2 |

X_train, X_test = train_test_split(X, y)

scaler.fit(X_train)                    # Aprende apenas do treino| `thalach` | Frequ√™ncia card√≠aca m√°xima alcan√ßada | ~71-202 |- **Atributos**: 13 features cl√≠nicas + 1 vari√°vel target

X_train_scaled = scaler.transform(X_train)

X_test_scaled = scaler.transform(X_test)| `exang` | Angina induzida por exerc√≠cio (1=sim, 0=n√£o) | 0-1 |



# ‚ùå ERRADO| `oldpeak` | Depress√£o de ST induzida por exerc√≠cio | 0-6.2 |- **Features Incluem**: Idade, sexo, tipo de dor no peito (cp), press√£o arterial em repouso (trestbps), colesterol s√©rico (chol), glicemia em jejum (fbs), resultados de ECG em repouso (restecg), frequ√™ncia card√≠aca m√°xima (thalach), angina induzida por exerc√≠cio (exang), depress√£o ST (oldpeak), inclina√ß√£o do segmento ST (slope), n√∫mero de vasos principais (ca), e talassemia (thal).1. **Separa√ß√£o de Features e Target**:

scaler.fit(X)                          # Vaza informa√ß√£o do teste

X_scaled = scaler.transform(X)| `slope` | Inclina√ß√£o do segmento ST no pico de exerc√≠cio | 0-2 |

X_train, X_test = train_test_split(X_scaled)

```| `ca` | N√∫mero de vasos principais coloridos (0-3) | 0-3 | ```python



---| `thal` | Talassemia (1=normal, 2=defeito fixo, 3=revers√≠vel) | 1-3 |



## üìà Resultados Obtidos#### Principais Features X = data.drop('target', axis=1) # 13 features



### M√©tricas de Performance### Vari√°vel-Alvo (Target)



| M√©trica                | Valor   |y = data['target'] # vari√°vel bin√°ria

|------------------------|---------|

| **Acur√°cia Global**    | 83.33%  |- **0:** Aus√™ncia de doen√ßa card√≠aca (Saud√°vel)

| **Precis√£o (Doente)**  | 84.6%   |

| **Recall (Doente)**    | 78.6%   |- **1:** Presen√ßa de doen√ßa card√≠aca (Doente)| Feature | Descri√ß√£o | ```

| **F1-Score**           | 0.81    |

_Nota: O dataset original possui target multi-classe (0-4). Foi realizada convers√£o para bin√°rio: 0 permanece 0, valores >0 foram convertidos para 1._| ---------- | -------------------------------------- |

### Matriz de Confus√£o

### Pr√©-processamento Aplicado| `age` | Idade do paciente |2. **Divis√£o Estratificada Train/Test**:

`````

                    Predito: Saud√°vel    Predito: Doente1. **Tratamento de Valores Ausentes**| `sex` | Sexo (1 = masculino, 0 = feminino) | ```python

Real: Saud√°vel 26 4

Real: Doente 6 24 - Identifica√ß√£o de valores nulos marcados como `'?'` no dataset original

````

   - Remo√ß√£o de 6 linhas com dados faltantes (303 ‚Üí 297 amostras)| `cp` | Tipo de dor no peito (0-3) | train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

**Interpreta√ß√£o:**

- **26 Verdadeiros Negativos:** Pacientes saud√°veis corretamente identificados2. **Transforma√ß√£o do Target**| `trestbps` | Press√£o arterial em repouso (mm Hg) | ```

- **24 Verdadeiros Positivos:** Pacientes doentes corretamente identificados

- **4 Falsos Positivos:** Saud√°veis classificados como doentes (exames extras)   - Convers√£o de multi-classe (0, 1, 2, 3, 4) para bin√°rio (0, 1)

- **6 Falsos Negativos:** Doentes classificados como saud√°veis ‚ö†Ô∏è (mais cr√≠tico)

   - Aplica√ß√£o: `lambda x: 1 if x > 0 else 0`| `chol` | Colesterol s√©rico (mg/dl) | - **Conjunto de Treino**: 237 amostras (80%)

### An√°lise no Contexto M√©dico

3. **Divis√£o Estratificada**| `fbs` | Glicemia em jejum > 120 mg/dl | - **Conjunto de Teste**: 60 amostras (20%)

**Recall de 78.6%:** O modelo detecta aproximadamente 4 em cada 5 pacientes doentes.

   - Split 80/20 com estratifica√ß√£o para manter propor√ß√£o de classes

**Falsos Negativos (6 casos):** Representa o erro mais cr√≠tico em medicina, pois pacientes doentes n√£o receberiam tratamento. Para uso cl√≠nico real, seria necess√°rio:

- Ajustar o threshold de decis√£o (reduzir de 0.5 para ~0.3-0.4)   - `stratify=y` no `train_test_split()`| `restecg` | Resultados eletrocardiogr√°ficos | - **Estratifica√ß√£o**: Mant√©m a propor√ß√£o de classes em ambos os conjuntos

- Combinar com avalia√ß√£o m√©dica profissional

- Usar como ferramenta de triagem, n√£o diagn√≥stico definitivo4. **Normaliza√ß√£o (StandardScaler)**| `thalach` | Frequ√™ncia card√≠aca m√°xima alcan√ßada |



**Falsos Positivos (4 casos):** Erro menos perigoso, resultando em exames complementares desnecess√°rios, mas sem risco √† vida.   - **CR√çTICO:** Aplicado **AP√ìS** a divis√£o treino/teste para evitar data leakage



### Comportamento do Treinamento   - Fit realizado exclusivamente nos dados de treino| `exang` | Angina induzida por exerc√≠cio |3. **Normaliza√ß√£o (StandardScaler)** - **PONTO CR√çTICO**:



- **Converg√™ncia:** Est√°vel nas primeiras 30-40 √©pocas   - Transform aplicado independentemente em treino e teste

- **Overfitting:** Detectado ap√≥s ~40 √©pocas (esperado para dataset pequeno)

- **Regulariza√ß√£o:** Dropout + L2 limitaram efetivamente o overfitting| `oldpeak` | Depress√£o de ST induzida por exerc√≠cio | ```python



------



## üí° Conclus√µes| `slope` | Inclina√ß√£o do segmento ST de pico | scaler = StandardScaler()



### Efic√°cia do Modelo## üß† Metodologia



O modelo **cumpriu todos os requisitos** estabelecidos:| `ca` | N√∫mero de vasos principais (0-3) | X_train_scaled = scaler.fit_transform(X_train) # Fit APENAS no treino



‚úÖ Rede Neural com 2 camadas ocultas (ReLU) e regulariza√ß√£o Dropout  ### Arquitetura da Rede Neural

‚úÖ Classifica√ß√£o bin√°ria com sa√≠da Sigmoid

‚úÖ Acur√°cia de 83.33% (realista para 297 amostras)  | `thal` | Talassemia (1-3) | X_test_scaled = scaler.transform(X_test) # Transform no teste

‚úÖ M√©tricas completas: Precis√£o, Recall e Matriz de Confus√£o

O modelo implementado segue uma arquitetura feedforward com as seguintes especifica√ß√µes:

### Import√¢ncia da Normaliza√ß√£o dos Dados

````

A normaliza√ß√£o foi **essencial** em tr√™s aspectos:

````

1. **Converg√™ncia:** Permitiu treinamento eficiente em ~30 √©pocas. Sem normaliza√ß√£o, features de alta magnitude (`chol`, `trestbps`) dominariam o gradiente, impedindo converg√™ncia.

Input Layer (13 neur√¥nios - features de entrada)### Etapas de Limpeza

2. **Preven√ß√£o de Data Leakage:** A ordem correta (Split ‚Üí Fit ‚Üí Transform) garantiu que estat√≠sticas do teste n√£o influenciassem o treino, simulando corretamente um cen√°rio de produ√ß√£o.

    ‚Üì

3. **Contribui√ß√£o Balanceada:** Todas as 13 features contribu√≠ram equilibradamente. Sem normaliza√ß√£o, features bin√°rias (`sex`, `fbs`) seriam ignoradas.

Dense Layer 1: 16 neur√¥nios#### ‚ö†Ô∏è Import√¢ncia da Normaliza√ß√£o dos Dados

### Performance Contextualizada

    - Ativa√ß√£o: ReLU

- **83.33% de acur√°cia** √© apropriado para um dataset de 297 amostras

- Performance competitiva com estudos acad√™micos usando o mesmo dataset UCI    - Regulariza√ß√£o: L2 (Œª=0.001)1. **Tratamento de Valores Ausentes**: O dataset original continha valores nulos representados pelo caractere `'?'`. Esses valores foram identificados durante a carga dos dados utilizando o par√¢metro `na_values='?'` do pandas.

- O overfitting observado (~40 √©pocas) √© esperado e foi adequadamente controlado

    - Dropout: 25%

### Aplicabilidade Cl√≠nica

    ‚ÜìA normaliza√ß√£o dos dados revelou-se **absolutamente essencial** para o sucesso do projeto:

**Uso Recomendado:**

- üè• Ferramenta de triagem inicial em unidades de sa√∫deDense Layer 2: 8 neur√¥nios

- üîç Sistema de apoio √† decis√£o para m√©dicos

- üìä Identifica√ß√£o de pacientes de risco para exames complementares    - Ativa√ß√£o: ReLU2. **Remo√ß√£o de Amostras Incompletas**: Aplicamos `dropna()` para remover todas as linhas com valores ausentes, resultando em **297 amostras v√°lidas** para an√°lise.



**Limita√ß√µes:**    - Regulariza√ß√£o: L2 (Œª=0.001)

- N√£o substitui diagn√≥stico m√©dico profissional

- Requer valida√ß√£o em datasets externos maiores    - Dropout: 25%**Por que normalizar?**

- Threshold de decis√£o deve ser ajustado para maximizar Recall

    ‚Üì

---

Output Layer: 1 neur√¥nio3. **Transforma√ß√£o da Vari√°vel Target**: A vari√°vel-alvo original era multi-classe (0, 1, 2, 3, 4), representando diferentes n√≠veis de severidade da doen√ßa. Convertemos para um problema bin√°rio aplicando a transforma√ß√£o:- Redes Neurais s√£o altamente sens√≠veis a caracter√≠sticas em escalas diferentes

## üöÄ Como Executar

    - Ativa√ß√£o: Sigmoid

### Pr√©-requisitos

    - Sa√≠da: Probabilidade [0, 1]   ```python- Features como `chol`(126-564) dominariam features como`sex` (0-1) sem normaliza√ß√£o

- Python 3.8+

- Jupyter Notebook ou JupyterLab```



### Instala√ß√£o   target_bin√°rio = 1 if target_original > 0 else 0- A converg√™ncia do gradiente descendente √© muito mais eficiente com dados normalizados



**1. Clone o reposit√≥rio:**### Configura√ß√£o de Treinamento

```bash

git clone https://github.com/AlexandreJr16/Heart-Diseases.git   ```

cd Heart-Diseases

```| Hiperpar√¢metro        | Valor                      | Justificativa                                          |



**2. Instale as depend√™ncias:**|-----------------------|----------------------------|--------------------------------------------------------|   ```

```bash

pip install -r requirements.txt| **Optimizer**         | Adam                       | Converg√™ncia adaptativa, eficiente para ANNs           |

````

| **Loss Function** | Binary Crossentropy | Padr√£o para classifica√ß√£o bin√°ria |**Por que esta ordem √© crucial?**

**3. Execute o notebook:**

`````bash| **Epochs**            | 100                        | Permite observa√ß√£o de overfitting                      |

jupyter notebook heart-diseases.ipynb

```| **Batch Size**        | 10                         | Balanceamento entre estabilidade e ru√≠do do gradiente  |#### Vari√°vel-Alvo (Target)- Realizar o scaling **antes** da divis√£o train/test causaria **data leakage**



**4. Execute as c√©lulas sequencialmente** (Shift + Enter) ou todas de uma vez (Cell ‚Üí Run All)| **L2 Regularization** | 0.001                      | Penaliza pesos grandes, promove generaliza√ß√£o          |



---| **Dropout Rate**      | 0.25 (25%)                 | Desativa neur√¥nios aleatoriamente, previne overfitting |- Informa√ß√µes estat√≠sticas do conjunto de teste (m√©dia e desvio padr√£o) "vazariam" para o conjunto de treino



## üõ† Tecnologias Utilizadas| **Validation Data**   | Test set (60 amostras)     | Monitoramento cont√≠nuo durante treinamento             |



| Tecnologia       | Vers√£o  | Fun√ß√£o                          |- **0:** Aus√™ncia de doen√ßa card√≠aca (Saud√°vel)- O scaler deve aprender os par√¢metros **exclusivamente** dos dados de treino

|------------------|---------|----------------------------------|

| **Python**       | 3.8+    | Linguagem de programa√ß√£o         |### Justificativas T√©cnicas

| **TensorFlow**   | 2.13.0+ | Framework de Deep Learning       |

| **Keras**        | API     | Constru√ß√£o da Rede Neural        |- **1:** Presen√ßa de doen√ßa card√≠aca (Doente)- Esta pr√°tica simula o cen√°rio real de produ√ß√£o, onde novos dados nunca foram vistos durante o treinamento

| **Scikit-learn** | 1.3.0+  | Pr√©-processamento e m√©tricas     |

| **Pandas**       | 2.0.0+  | Manipula√ß√£o de dados             |**1. Fun√ß√£o de Ativa√ß√£o ReLU**

| **NumPy**        | 1.24.0+ | Computa√ß√£o num√©rica              |

| **Matplotlib**   | 3.7.0+  | Visualiza√ß√£o de dados            |- Evita vanishing gradient---### Fase 3Ô∏è‚É£: Constru√ß√£o do Modelo (ANN)

| **Seaborn**      | 0.12.0+ | Visualiza√ß√£o estat√≠stica         |

- Computacionalmente eficiente

---

- Boa performance em problemas de classifica√ß√£o## üõ†Ô∏è MetodologiaDesenvolvemos uma Rede Neural Artificial feedforward com a seguinte arquitetura:

## üìö Refer√™ncias



- **Janosi, A., Steinbrunn, W., Pfisterer, M., & Detrano, R. (1988).** Heart Disease Data Set. UCI Machine Learning Repository.

- **Goodfellow, I., Bengio, Y., & Courville, A. (2016).** Deep Learning. MIT Press.**2. Regulariza√ß√£o Combinada (L2 + Dropout)**O projeto foi estruturado em **cinco fases principais**, seguindo um pipeline rigoroso de Data Science para garantir a validade e a replicabilidade dos resultados.```

- **G√©ron, A. (2019).** Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow. O'Reilly Media.

- **L2:** Penaliza pesos elevados, for√ßa distribui√ß√£o mais suave

---

- **Dropout:** Desativa 25% dos neur√¥nios a cada itera√ß√£o, reduz co-adapta√ß√£oCamada de Entrada: 13 neur√¥nios (features)

## üë• Autores



**Alexandre Pereira de Souza Junior**

**Leonardo Brand√£o**  **3. Sigmoid na Sa√≠da**### Fase 1Ô∏è‚É£: An√°lise Explorat√≥ria de Dados (EDA) ‚Üì

**Vithor Vit√≥rio**

- Comprime sa√≠da para intervalo [0, 1]

**Institui√ß√£o:** Universidade Federal de Alagoas (UFAL)

**Disciplina:** Fundamentos de Intelig√™ncia Artificial (FIA)  - Interpret√°vel como probabilidade de doen√ßaCamada Oculta 1: 16 neur√¥nios

**Professor:** Edjard Mota

- Threshold de decis√£o em 0.5 (pode ser ajustado)

---

Antes de qualquer modelagem, uma an√°lise detalhada foi conduzida para entender a natureza dos dados: - Ativa√ß√£o: ReLU

<div align="center">

### Import√¢ncia da Normaliza√ß√£o dos Dados

**Desenvolvido para a disciplina de Fundamentos de IA - 2025** üß†‚ù§Ô∏è

    - Regulariza√ß√£o: L2 (lambda=0.001)

</div>

A normaliza√ß√£o √© **absolutamente cr√≠tica** para o sucesso de Redes Neurais:

- **Balanceamento de Classes**: Verifica√ß√£o da distribui√ß√£o entre pacientes saud√°veis e doentes - Dropout: 25%

#### Por que Normalizar?

- **Matriz de Correla√ß√£o**: Identifica√ß√£o de rela√ß√µes lineares entre as features ‚Üì

- **Escalas Divergentes:** Features possuem magnitudes muito diferentes (`chol`: 126-564 vs `sex`: 0-1)

- **Domin√¢ncia de Features:** Sem normaliza√ß√£o, atributos com valores maiores dominam o c√°lculo do gradiente- **Estat√≠sticas Descritivas**: Compreens√£o da distribui√ß√£o de cada atributo cl√≠nicoCamada Oculta 2: 8 neur√¥nios

- **Converg√™ncia:** Dados normalizados permitem converg√™ncia muito mais r√°pida e est√°vel

  - Ativa√ß√£o: ReLU

#### Por que a Ordem Importa?

### Fase 2Ô∏è‚É£: Pr√©-processamento e Preven√ß√£o de Data Leakage - Regulariza√ß√£o: L2 (lambda=0.001)

**‚ö†Ô∏è PREVEN√á√ÉO DE DATA LEAKAGE**

    - Dropout: 25%

**Ordem CORRETA:**

```pythonEsta foi a etapa t√©cnica **mais cr√≠tica** do projeto, onde seguimos rigorosamente as melhores pr√°ticas de Machine Learning. ‚Üì

1. Split treino/teste

2. scaler.fit_transform(X_train)    # Aprende m√©dia/std do TREINOCamada de Sa√≠da: 1 neur√¥nio

3. scaler.transform(X_test)          # Aplica par√¢metros do TREINO no TESTE

```#### Pipeline de Pr√©-processamento - Ativa√ß√£o: Sigmoid (probabilidade de doen√ßa)



**Ordem ERRADA (causa data leakage):**````

```python

1. scaler.fit_transform(X_completo)  # ‚ùå Informa√ß√£o do teste vaza para treino1. **Separa√ß√£o de Features e Target**:

2. Split treino/teste

```   ```python#### Configura√ß√£o de Treinamento



**Consequ√™ncia do Data Leakage:**   X = data.drop('target', axis=1)  # 13 features

- Estat√≠sticas do teste (m√©dia, desvio padr√£o) influenciam a normaliza√ß√£o do treino

- Modelo tem acesso indireto a informa√ß√µes que s√≥ veria na produ√ß√£o   y = data['target']               # vari√°vel bin√°ria| Par√¢metro          | Valor                       |

- Resultados s√£o otimistas e n√£o generalizam para dados reais

   ```| ------------------ | --------------------------- |

---

| **Optimizer**      | Adam                        |

## üìà Resultados

2. **Divis√£o Estratificada Train/Test**:| **Loss Function**  | Binary Crossentropy         |

### M√©tricas de Performance

   ```python| **Epochs**         | 100                         |

| M√©trica                  | Valor   | Interpreta√ß√£o                                        |

|--------------------------|---------|------------------------------------------------------|   train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)| **Batch Size**     | 10                          |

| **Acur√°cia Global**      | 83.33%  | 50 de 60 pacientes corretamente classificados        |

| **Precis√£o (Doente)**    | 84.6%   | Quando prev√™ doen√ßa, est√° correto em 84.6% dos casos|   ```| **Regularization** | L2 (0.001) + Dropout (0.25) |

| **Recall (Doente)**      | 78.6%   | Detecta 78.6% dos pacientes realmente doentes        |

| **F1-Score (Doente)**    | 0.81    | M√©dia harm√¥nica entre Precis√£o e Recall              |   - **Conjunto de Treino**: 237 amostras (80%)| **Valida√ß√£o**      | Conjunto de teste           |



### Matriz de Confus√£o   - **Conjunto de Teste**: 60 amostras (20%)



```   - **Estratifica√ß√£o**: Mant√©m a propor√ß√£o de classes em ambos os conjuntos#### Estrat√©gia de Regulariza√ß√£o

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê

‚îÇ                     ‚îÇ Previsto: Saud√°vel‚îÇ Previsto: Doente‚îÇ

‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§

‚îÇ Real: Saud√°vel (30) ‚îÇ     26 (TN) ‚úÖ   ‚îÇ      4 (FP) ‚ö†Ô∏è   ‚îÇ3. **Normaliza√ß√£o (StandardScaler)** - **PONTO CR√çTICO**:- **L2 Regularization**: Penaliza pesos muito altos, promovendo uma distribui√ß√£o mais suave dos pesos

‚îÇ Real: Doente (30)   ‚îÇ      6 (FN) ‚ùå   ‚îÇ     24 (TP) ‚úÖ   ‚îÇ

‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ```python- **Dropout (25%)**: Durante o treino, desativa aleatoriamente 25% dos neur√¥nios em cada camada oculta, for√ßando a rede a aprender representa√ß√µes mais robustas e reduzindo a depend√™ncia de neur√¥nios espec√≠ficos

`````

scaler = StandardScaler()

**Legenda:**

- **TN (True Negative):** 26 pacientes saud√°veis corretamente identificados X_train_scaled = scaler.fit_transform(X_train) # Fit APENAS no treino### Fase 4Ô∏è‚É£: Treinamento e An√°lise de Overfitting

- **TP (True Positive):** 24 pacientes doentes corretamente identificados

- **FP (False Positive):** 4 pacientes saud√°veis incorretamente classificados como doentes X_test_scaled = scaler.transform(X_test) # Transform no teste

- **FN (False Negative):** 6 pacientes doentes incorretamente classificados como saud√°veis

  ```O modelo foi treinado por 100 √©pocas com monitoramento cont√≠nuo das m√©tricas de treino e valida√ß√£o. Os gr√°ficos de hist√≥rico revelaram um padr√£o cl√°ssico de **overfitting** ap√≥s aproximadamente 30-40 √©pocas:

  ```

### An√°lise Cr√≠tica no Contexto M√©dico

#### ‚ö†Ô∏è Falsos Negativos: O Erro Mais Cr√≠tico

#### ‚ö†Ô∏è Import√¢ncia da Normaliza√ß√£o dos Dados- **Acur√°cia de Treino**: Continuou aumentando at√© ~90%

Em aplica√ß√µes m√©dicas, os **Falsos Negativos** (FN) representam o maior risco:

- **Acur√°cia de Valida√ß√£o**: Estagnou em ~83% e apresentou flutua√ß√µes

- **6 pacientes doentes** foram classificados como saud√°veis

- **Consequ√™ncia:** Esses pacientes n√£o receberiam tratamento adequadoA normaliza√ß√£o dos dados revelou-se **absolutamente essencial** para o sucesso do projeto:- **Perda de Valida√ß√£o**: Come√ßou a aumentar enquanto a perda de treino diminu√≠a

- **Custo:** Potencialmente fatal - progress√£o da doen√ßa sem interven√ß√£o

#### ‚úÖ Falsos Positivos: Erro Menos Perigoso

**Por que normalizar?\*\***Interpreta√ß√£o**: Este comportamento √© **esperado e normal\*\* para um dataset pequeno (237 amostras de treino). As t√©cnicas de regulariza√ß√£o (Dropout + L2) foram eficazes em limitar o overfitting, mas n√£o em elimin√°-lo completamente.

- **4 pacientes saud√°veis** foram classificados como doentes

- **Consequ√™ncia:** Encaminhamento para exames complementares desnecess√°rios- Redes Neurais s√£o altamente sens√≠veis a caracter√≠sticas em escalas diferentes

- **Custo:** Financeiro e emocional, mas n√£o fatal

- Features como `chol` (126-564) dominariam features como `sex` (0-1) sem normaliza√ß√£o### Fase 5Ô∏è‚É£: Avalia√ß√£o Final e An√°lise Cr√≠tica

#### Recall (Sensibilidade): M√©trica Priorit√°ria

- A converg√™ncia do gradiente descendente √© muito mais eficiente com dados normalizados

- **Recall de 78.6%** significa que o modelo detecta aproximadamente 4 em cada 5 pacientes doentes

- Em triagem m√©dica, √© prefer√≠vel maximizar o Recall (detectar o m√°ximo de doentes)A avalia√ß√£o final utilizou m√∫ltiplas m√©tricas para fornecer uma vis√£o completa da performance do modelo, com √™nfase especial nas m√©tricas mais relevantes para o contexto m√©dico.

- **Trade-off:** Aumentar Recall geralmente reduz Precis√£o (mais falsos positivos)

**Por que esta ordem √© crucial?**

#### Estrat√©gias de Melhoria

- Realizar o scaling **antes** da divis√£o train/test causaria **data leakage**A abordagem utiliza t√©cnicas de **Deep Learning** para analisar 13 atributos cl√≠nicos e fisiol√≥gicos de pacientes, construindo uma Rede Neural Artificial (ANN) feedforward capaz de realizar predi√ß√µes com base em dados hist√≥ricos.

1. **Ajuste de Threshold:** Reduzir de 0.5 para ~0.3-0.4 aumentaria Recall

2. **Class Weights:** Penalizar mais erros na classe "doente"- Informa√ß√µes estat√≠sticas do conjunto de teste (m√©dia e desvio padr√£o) "vazariam" para o conjunto de treino

3. **SMOTE:** Balanceamento sint√©tico se houvesse desbalanceamento

4. **Ensemble Methods:** Combinar m√∫ltiplos modelos para decis√£o final- O scaler deve aprender os par√¢metros **exclusivamente** dos dados de treino---

### An√°lise do Treinamento- Esta pr√°tica simula o cen√°rio real de produ√ß√£o, onde novos dados nunca foram vistos durante o treinamento

**Observa√ß√µes dos Gr√°ficos de Aprendizado:**## üî¨ Dataset: Origem, Estrutura e Limpeza

- **Converg√™ncia:** Est√°vel nas primeiras 30-40 √©pocas### Fase 3Ô∏è‚É£: Constru√ß√£o do Modelo (ANN)

- **Overfitting Detectado:** Ap√≥s ~40 √©pocas

  - Acur√°cia de treino continua subindo (~90%)### Fonte de Dados

  - Acur√°cia de valida√ß√£o estagna (~83%)

  - Perda de valida√ß√£o come√ßa a aumentarDesenvolvemos uma Rede Neural Artificial feedforward com a seguinte arquitetura:

- **Efic√°cia da Regulariza√ß√£o:** Dropout + L2 limitaram, mas n√£o eliminaram o overfitting

O dataset utilizado √© o cl√°ssico **Cleveland Heart Disease Database** do reposit√≥rio UCI Machine Learning, acess√≠vel via:

**Interpreta√ß√£o:**

Este padr√£o √© **esperado e normal** para datasets pequenos (237 amostras de treino). A regulariza√ß√£o funcionou adequadamente, mas datasets maiores seriam necess√°rios para eliminar completamente o overfitting.````

---Camada de Entrada: 13 neur√¥nios (features)```

## üí° Conclus√µes ‚Üìhttp://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data

### Efic√°cia do ModeloCamada Oculta 1: 16 neur√¥nios```

O modelo desenvolvido **atendeu plenamente aos requisitos estabelecidos**: - Ativa√ß√£o: ReLU

‚úÖ **Arquitetura Implementada:** Rede Neural Feedforward com 2 camadas ocultas (16-8 neur√¥nios) - Regulariza√ß√£o: L2 (lambda=0.001)**Nota Importante sobre a Escolha do Dataset**: Durante a fase inicial do projeto, identificamos uma discrep√¢ncia entre o dataset sugerido no material de apoio (Kaggle, 1025 amostras) e o dataset utilizado no notebook de refer√™ncia do professor. Ap√≥s an√°lise cr√≠tica, confirmamos que o dataset correto para este projeto √© o **UCI Cleveland original (303 amostras)**, que representa o benchmark hist√≥rico para pesquisas em classifica√ß√£o de doen√ßas card√≠acas.

‚úÖ **Ativa√ß√µes Corretas:** ReLU nas camadas ocultas, Sigmoid na sa√≠da

‚úÖ **Regulariza√ß√£o:** Dropout (25%) aplicado ap√≥s cada camada oculta - Dropout: 25%

‚úÖ **Classifica√ß√£o Bin√°ria:** Target convertido corretamente (0/1)

‚úÖ **M√©tricas Completas:** Acur√°cia (83.3%), Precis√£o (84.6%), Recall (78.6%), Matriz de Confus√£o ‚Üì### Estrutura do Dataset

### Performance no Contexto RealCamada Oculta 2: 8 neur√¥nios

**Acur√°cia de 83.3%:** Resultado realista e apropriado para: - Ativa√ß√£o: ReLU- **Amostras Originais**: 303 pacientes

- Dataset pequeno (297 amostras)

- Problema complexo (diagn√≥stico m√©dico) - Regulariza√ß√£o: L2 (lambda=0.001)- **Atributos**: 13 features cl√≠nicas + 1 vari√°vel target

- Benchmark competitivo com estudos acad√™micos usando o mesmo dataset UCI

  - Dropout: 25%- **Features Incluem**: Idade, sexo, tipo de dor no peito (cp), press√£o arterial em repouso (trestbps), colesterol s√©rico (chol), glicemia em jejum (fbs), resultados de ECG em repouso (restecg), frequ√™ncia card√≠aca m√°xima (thalach), angina induzida por exerc√≠cio (exang), depress√£o ST (oldpeak), inclina√ß√£o do segmento ST (slope), n√∫mero de vasos principais (ca), e talassemia (thal).

**Compara√ß√£o com Literatura:**

- Estudos similares no dataset UCI Cleveland reportam acur√°cias entre 80-85% ‚Üì

- Datasets maiores (Kaggle, 1025 amostras) alcan√ßam ~92-93%

Camada de Sa√≠da: 1 neur√¥nio#### Principais Features

### Import√¢ncia da Normaliza√ß√£o dos Dados

    - Ativa√ß√£o: Sigmoid (probabilidade de doen√ßa)

A normaliza√ß√£o revelou-se **essencial** em tr√™s dimens√µes:

`````| Feature    | Descri√ß√£o                              |

**1. Converg√™ncia do Treinamento**

- Sem normaliza√ß√£o: features de alta magnitude dominam o gradiente| ---------- | -------------------------------------- |

- Com normaliza√ß√£o: converg√™ncia est√°vel em ~30 √©pocas

- **Resultado:** Treinamento vi√°vel e eficiente#### Configura√ß√£o de Treinamento| `age`      | Idade do paciente                      |



**2. Preven√ß√£o de Data Leakage**| `sex`      | Sexo (1 = masculino, 0 = feminino)     |

- Ordem correta: Split ‚Üí Fit (treino) ‚Üí Transform (treino e teste)

- Garante que estat√≠sticas do teste n√£o influenciem o treino| Par√¢metro          | Valor                       || `cp`       | Tipo de dor no peito (0-3)             |

- **Resultado:** Modelo validado corretamente

| ------------------ | --------------------------- || `trestbps` | Press√£o arterial em repouso (mm Hg)    |

**3. Contribui√ß√£o Balanceada de Features**

- Todas as 13 features contribuem de forma equilibrada| **Optimizer**      | Adam                        || `chol`     | Colesterol s√©rico (mg/dl)              |

- Sem normaliza√ß√£o: `chol`, `trestbps` dominariam completamente

- **Resultado:** Acur√°cia de 83.3% reflete aprendizado real| **Loss Function**  | Binary Crossentropy         || `fbs`      | Glicemia em jejum > 120 mg/dl          |



### Li√ß√µes Aprendidas| **Epochs**         | 100                         || `restecg`  | Resultados eletrocardiogr√°ficos        |



1. **Datasets Pequenos Exigem Regulariza√ß√£o Agressiva**| **Batch Size**     | 10                          || `thalach`  | Frequ√™ncia card√≠aca m√°xima alcan√ßada   |

   - Dropout (25%) + L2 (0.001) foram eficazes mas n√£o eliminaram overfitting

   - Early Stopping em ~40 √©pocas seria ben√©fico| **Regularization** | L2 (0.001) + Dropout (0.25) || `exang`    | Angina induzida por exerc√≠cio          |



2. **Ordem das Opera√ß√µes √© Cr√≠tica**| **Valida√ß√£o**      | Conjunto de teste           || `oldpeak`  | Depress√£o de ST induzida por exerc√≠cio |

   - Data leakage invalida completamente os resultados

   - Pipeline correto: Split ‚Üí Fit ‚Üí Transform| `slope`    | Inclina√ß√£o do segmento ST de pico      |



3. **M√©tricas Contextuais > Acur√°cia Global**#### Estrat√©gia de Regulariza√ß√£o| `ca`       | N√∫mero de vasos principais (0-3)       |

   - Em medicina, Recall √© mais importante que Acur√°cia

   - Matriz de Confus√£o revela insights que m√©trica √∫nica n√£o mostra| `thal`     | Talassemia (1-3)                       |



4. **Overfitting √© Esperado, N√£o um Fracasso**- **L2 Regularization**: Penaliza pesos muito altos, promovendo uma distribui√ß√£o mais suave dos pesos

   - Com 237 amostras de treino, overfitting ap√≥s 40 √©pocas √© inevit√°vel

   - O importante √© limit√°-lo via regulariza√ß√£o- **Dropout (25%)**: Durante o treino, desativa aleatoriamente 25% dos neur√¥nios em cada camada oculta, for√ßando a rede a aprender representa√ß√µes mais robustas e reduzindo a depend√™ncia de neur√¥nios espec√≠ficos### Etapas de Limpeza



### Aplicabilidade Cl√≠nica



**Uso Recomendado:**### Fase 4Ô∏è‚É£: Treinamento e An√°lise de Overfitting1. **Tratamento de Valores Ausentes**: O dataset original continha valores nulos representados pelo caractere `'?'`. Esses valores foram identificados durante a carga dos dados utilizando o par√¢metro `na_values='?'` do pandas.

- üè• Ferramenta de **triagem inicial** em unidades de sa√∫de

- üîç **Sistema de apoio √† decis√£o** para m√©dicos (n√£o diagn√≥stico definitivo)

- üìä **Identifica√ß√£o de pacientes de risco** para exames complementares

O modelo foi treinado por 100 √©pocas com monitoramento cont√≠nuo das m√©tricas de treino e valida√ß√£o. Os gr√°ficos de hist√≥rico revelaram um padr√£o cl√°ssico de **overfitting** ap√≥s aproximadamente 30-40 √©pocas:2. **Remo√ß√£o de Amostras Incompletas**: Aplicamos `dropna()` para remover todas as linhas com valores ausentes, resultando em **297 amostras v√°lidas** para an√°lise.

**Limita√ß√µes para Uso Cl√≠nico:**

- Requer valida√ß√£o em datasets externos maiores

- 6 Falsos Negativos (21% dos doentes) √© alto para uso aut√¥nomo

- Deve ser combinado com avalia√ß√£o m√©dica profissional- **Acur√°cia de Treino**: Continuou aumentando at√© ~90%3. **Transforma√ß√£o da Vari√°vel Target**: A vari√°vel-alvo original era multi-classe (0, 1, 2, 3, 4), representando diferentes n√≠veis de severidade da doen√ßa. Convertemos para um problema bin√°rio aplicando a transforma√ß√£o:



### Pr√≥ximos Passos- **Acur√°cia de Valida√ß√£o**: Estagnou em ~83% e apresentou flutua√ß√µes   ```python



- [ ] Implementar K-Fold Cross-Validation para resultados mais robustos- **Perda de Valida√ß√£o**: Come√ßou a aumentar enquanto a perda de treino diminu√≠a   target_bin√°rio = 1 if target_original > 0 else 0

- [ ] Testar arquiteturas alternativas (3 camadas, diferentes configura√ß√µes)

- [ ] Ajustar threshold de decis√£o para maximizar Recall````

- [ ] Comparar com modelos baseline (Random Forest, SVM, XGBoost)

- [ ] An√°lise de import√¢ncia de features (SHAP values)**Interpreta√ß√£o**: Este comportamento √© **esperado e normal** para um dataset pequeno (237 amostras de treino). As t√©cnicas de regulariza√ß√£o (Dropout + L2) foram eficazes em limitar o overfitting, mas n√£o em elimin√°-lo completamente.

- [ ] Coletar mais dados para reduzir overfitting

#### Vari√°vel-Alvo (Target)

---

### Fase 5Ô∏è‚É£: Avalia√ß√£o Final e An√°lise Cr√≠tica

## üöÄ Como Executar

- **0:** Aus√™ncia de doen√ßa card√≠aca (Saud√°vel)

### Pr√©-requisitos

A avalia√ß√£o final utilizou m√∫ltiplas m√©tricas para fornecer uma vis√£o completa da performance do modelo, com √™nfase especial nas m√©tricas mais relevantes para o contexto m√©dico.- **1:** Presen√ßa de doen√ßa card√≠aca (Doente)

- **Python:** 3.8 ou superior

- **Jupyter Notebook ou JupyterLab**---

- **Git** (para clonar o reposit√≥rio)

## üìä Resultados e An√°lise Cr√≠tica## üî¨ Metodologia

### Passo a Passo

### M√©tricas de PerformanceO projeto foi estruturado em **quatro fases principais**, seguindo um pipeline rigoroso de Data Science.

**1. Clone o Reposit√≥rio**

| M√©trica | Valor |### Fase 1Ô∏è‚É£: An√°lise Explorat√≥ria de Dados (EDA)

```bash

git clone https://github.com/AlexandreJr16/Heart-Diseases.git|---------|-------|

cd Heart-Diseases

```| **Acur√°cia Global** | 83.3% |Antes de qualquer modelagem, uma an√°lise detalhada foi conduzida para entender a natureza dos dados.



**2. Instale as Depend√™ncias**| **Precis√£o (Doente)** | 84.6% |



```bash| **Recall (Doente)** | 78.6% |#### Principais Descobertas

pip install -r requirements.txt

```| **F1-Score (Doente)** | 0.81 |



Ou instale manualmente:‚úÖ **Balanceamento Perfeito**



```bash### Matriz de Confus√£o

pip install pandas numpy tensorflow scikit-learn matplotlib seaborn

```- 526 inst√¢ncias da classe '1' (doente)



**3. Execute o Notebook**```- 499 inst√¢ncias da classe '0' (saud√°vel)



Op√ß√£o A - VS Code:                 Predito: Saud√°vel    Predito: Doente- Valida√ß√£o da **Acur√°cia** como m√©trica confi√°vel

```bash

code heart-diseases.ipynbReal: Saud√°vel          26                   4

```

Real: Doente             6                  24‚úÖ **Qualidade dos Dados**

Op√ß√£o B - Jupyter Notebook:

```bash```

jupyter notebook heart-diseases.ipynb

```- Dataset completo, **sem valores nulos**



Op√ß√£o C - Jupyter Lab:**Interpreta√ß√£o Detalhada**:- N√£o exigiu etapas de imputation

```bash

jupyter lab heart-diseases.ipynb- Pronto para modelagem ap√≥s scaling

```

1. **Verdadeiros Negativos (26)**: Pacientes saud√°veis corretamente classificados como saud√°veis

**4. Execute as C√©lulas**

2. **Falsos Positivos (4)**: Pacientes saud√°veis incorretamente classificados como doentes### Fase 2Ô∏è‚É£: Pr√©-Processamento e Preven√ß√£o de Data Leakage

- Execute todas de uma vez: `Cell ‚Üí Run All`

- Execute c√©lula por c√©lula: `Shift + Enter`3. **Falsos Negativos (6)**: Pacientes doentes incorretamente classificados como saud√°veis ‚ö†Ô∏è



### Estrutura do Projeto4. **Verdadeiros Positivos (24)**: Pacientes doentes corretamente classificados como doentesEsta foi a etapa t√©cnica mais cr√≠tica do projeto.



```### üè• An√°lise Cr√≠tica no Contexto M√©dico#### Divis√£o de Dados

Heart-Diseases/

‚îÇ#### Import√¢ncia do Recall (78.6%)```python

‚îú‚îÄ‚îÄ heart-diseases.ipynb    # Notebook principal com an√°lise completa

‚îú‚îÄ‚îÄ heart.csv               # Dataset local (backup)Train: 80% | Test: 20%

‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias Python

‚îú‚îÄ‚îÄ README.md              # Este arquivoEm aplica√ß√µes m√©dicas de diagn√≥stico, o **Recall** (sensibilidade) √© frequentemente mais cr√≠tico que a precis√£o:Stratified Split (mant√©m propor√ß√£o das classes)

‚îî‚îÄ‚îÄ .github/

    ‚îî‚îÄ‚îÄ copilot-instructions.md  # Instru√ß√µes do projeto````

```

- Um Recall de 78.6% significa que o modelo detectou corretamente **78.6% dos casos reais de doen√ßa card√≠aca**

---

- Os **6 Falsos Negativos** representam o maior risco: pacientes doentes que n√£o receberiam o tratamento adequado se confi√°ssemos apenas no modelo#### Normaliza√ß√£o (StandardScaler)

## üõ†Ô∏è Tecnologias Utilizadas



### Bibliotecas Principais

#### Falsos Positivos vs. Falsos Negativos**Por que √© crucial?**

| Biblioteca         | Vers√£o  | Fun√ß√£o                                              |

|--------------------|---------|-----------------------------------------------------|Redes Neurais s√£o altamente sens√≠veis a caracter√≠sticas em escalas diferentes:

| **Python**         | 3.8+    | Linguagem de programa√ß√£o base                       |

| **TensorFlow**     | 2.13.0+ | Framework de Deep Learning                          |- **Falsos Positivos (4)**: Pacientes saud√°veis que seriam encaminhados para exames adicionais. Embora cause custos e ansiedade, √© o "erro menos perigoso"

| **Keras**          | (API)   | API de alto n√≠vel para constru√ß√£o de redes neurais |

| **Scikit-learn**   | 1.3.0+  | Pr√©-processamento, m√©tricas e valida√ß√£o            |- **Falsos Negativos (6)**: Pacientes doentes que receberiam alta m√©dica. Este √© o erro cr√≠tico que pode ter consequ√™ncias fatais- `age`: 29-77

| **Pandas**         | 2.0.0+  | Manipula√ß√£o e an√°lise de dados                     |

| **NumPy**          | 1.24.0+ | Computa√ß√£o num√©rica e arrays                       |- `chol`: 126-564

| **Matplotlib**     | 3.7.0+  | Visualiza√ß√£o de dados (gr√°ficos)                   |

| **Seaborn**        | 0.12.0+ | Visualiza√ß√£o estat√≠stica avan√ßada                  |#### Conclus√£o sobre Performance



### Ferramentas de Desenvolvimento**Metodologia Rigorosa para Prevenir Data Leakage:**



- **Jupyter Notebook:** Ambiente interativo de desenvolvimento- Uma acur√°cia de **83.3%** √© **realista e apropriada** para um dataset de 297 amostras

- **Git/GitHub:** Controle de vers√£o e colabora√ß√£o

- **VS Code:** Editor de c√≥digo (opcional)- O desempenho √© competitivo com estudos acad√™micos similares usando o mesmo dataset UCI```python



---- Para uso cl√≠nico real, o modelo precisaria de:# ‚úÖ CORRETO: Fit apenas no treino



## üìö Refer√™ncias  - Ajuste do threshold de decis√£o (reduzir de 0.5 para ~0.3) para aumentar o Recallscaler.fit(X_train)



### Dataset  - Valida√ß√£o em datasets externos maioresX_train_scaled = scaler.transform(X_train)



- **Janosi, A., Steinbrunn, W., Pfisterer, M., & Detrano, R. (1988).** Heart Disease Data Set. UCI Machine Learning Repository. Dispon√≠vel em: http://archive.ics.uci.edu/ml/datasets/Heart+Disease  - Integra√ß√£o como ferramenta de triagem, n√£o diagn√≥stico definitivoX_test_scaled = scaler.transform(X_test)



### Fundamenta√ß√£o Te√≥rica



- **Goodfellow, I., Bengio, Y., & Courville, A. (2016).** *Deep Learning*. MIT Press.### üìà An√°lise do Treinamento# ‚ùå ERRADO: Fit em todos os dados (causa data leakage)

- **G√©ron, A. (2019).** *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* (2nd ed.). O'Reilly Media.

- **Chollet, F. (2017).** *Deep Learning with Python*. Manning Publications.scaler.fit(X)  # N√ÉO FAZER ISSO!



### Documenta√ß√£o T√©cnicaOs gr√°ficos de hist√≥rico de treinamento revelaram:```



- TensorFlow Documentation: https://www.tensorflow.org/api_docs

- Keras API Reference: https://keras.io/api/

- Scikit-learn Documentation: https://scikit-learn.org/stable/documentation.html- **Converg√™ncia**: O modelo convergiu de forma est√°vel nas primeiras 40 √©pocas### Fase 3Ô∏è‚É£: Arquitetura e Treinamento do Modelo



---- **Overfitting**: Detectado ap√≥s ~40 √©pocas, com diverg√™ncia entre treino e valida√ß√£o



## üë• Autores- **Efic√°cia da Regulariza√ß√£o**: Dropout e L2 limitaram o overfitting, mas n√£o o eliminaram completamente#### Arquitetura da Rede Neural



**Alexandre Pereira de Souza Junior**

**Leonardo Brand√£o**

**Vithor Vit√≥rio****Contexto**: Este padr√£o √© esperado e normal para datasets pequenos (237 amostras de treino).```



**Institui√ß√£o:** Universidade Federal de Alagoas (UFAL)  Input Layer (13 features)

**Disciplina:** Fundamentos de Intelig√™ncia Artificial (FIA)

**Professor:** Edjard Mota  ---        ‚Üì

**Per√≠odo:** 2¬∫ Semestre de 2025

Dense(16, ReLU) + L2 Regularization

---

## üéØ Conclus√£o        ‚Üì

## üìÑ Licen√ßa

Dropout(0.25)

Este projeto est√° sob a licen√ßa MIT. Consulte o arquivo `LICENSE` para mais detalhes.

### Efic√°cia do Modelo        ‚Üì

---

Dense(8, ReLU) + L2 Regularization

## üìß Contato

O modelo desenvolvido **atendeu plenamente aos requisitos do projeto**:        ‚Üì

Para d√∫vidas, sugest√µes ou colabora√ß√µes:

Dropout(0.25)

- **GitHub:** [@AlexandreJr16](https://github.com/AlexandreJr16)

- **Reposit√≥rio:** [Heart-Diseases](https://github.com/AlexandreJr16/Heart-Diseases)‚úÖ Constru√ß√£o de uma ANN feedforward com 2 camadas ocultas (ReLU) e regulariza√ß√£o Dropout          ‚Üì



---‚úÖ Camada de sa√≠da com ativa√ß√£o sigmoid para classifica√ß√£o bin√°ria  Output(1, Sigmoid) ‚Üí Probabilidade [0, 1]



<div align="center">‚úÖ Avalia√ß√£o utilizando Acur√°cia (83.3%), Precis√£o (84.6%), Recall (78.6%) e Matriz de Confus√£o  ```



**‚≠ê Se este projeto foi √∫til para seus estudos, considere dar uma estrela no reposit√≥rio!**‚úÖ Entrega de um classificador funcional com an√°lise realista de desempenho



Desenvolvido com dedica√ß√£o para a disciplina de Fundamentos de IA üß†‚ù§Ô∏è#### Configura√ß√£o de Treinamento



</div>### Import√¢ncia da Normaliza√ß√£o dos Dados


| Par√¢metro          | Valor                       |

A normaliza√ß√£o dos dados revelou-se **absolutamente essencial** para o sucesso do projeto:| ------------------ | --------------------------- |

| **Optimizer**      | Adam                        |

1. **Converg√™ncia do Treinamento**: Sem normaliza√ß√£o, as features com escalas maiores (ex: colesterol ~200-300) dominariam o gradiente, dificultando ou impedindo a converg√™ncia da rede neural.| **Loss Function**  | Binary Crossentropy         |

| **Epochs**         | 100                         |

2. **Preven√ß√£o de Data Leakage**: A aplica√ß√£o correta do StandardScaler (fit no treino, transform no teste) garantiu que o modelo n√£o tivesse acesso a informa√ß√µes futuras, simulando adequadamente um cen√°rio de produ√ß√£o.| **Batch Size**     | 10                          |

| **Regularization** | L2 (0.001) + Dropout (0.25) |

3. **Performance**: A normaliza√ß√£o permitiu que todas as 13 features contribu√≠ssem de forma balanceada para as predi√ß√µes, resultando na acur√°cia de 83.3%.

#### T√©cnicas de Regulariza√ß√£o

### Li√ß√µes Aprendidas

- **Dropout:** Previne overfitting desativando aleatoriamente 25% dos neur√¥nios

- Datasets pequenos requerem t√©cnicas agressivas de regulariza√ß√£o- **L2 Regularization:** Penaliza pesos grandes, promovendo generaliza√ß√£o

- A ordem das opera√ß√µes no pipeline de pr√©-processamento √© cr√≠tica para a validade do modelo- **Validation Split:** Monitoramento cont√≠nuo da performance no teste

- M√©tricas contextuais (Recall em medicina) s√£o mais importantes que acur√°cia global

- Overfitting √© um fen√¥meno esperado e deve ser monitorado, n√£o necessariamente eliminado---



---## üìà Resultados



## üöÄ Instru√ß√µes de Execu√ß√£o### üéØ Performance Geral



### Pr√©-requisitos```

Acur√°cia no Conjunto de Teste: 92.68%

- Python 3.8+```

- Jupyter Notebook ou JupyterLab

Isso significa que o modelo classificou corretamente **quase 93 de cada 100 pacientes** no conjunto de teste.

### Passos para Execu√ß√£o

### üè• An√°lise da Matriz de Confus√£o

1. **Clone o reposit√≥rio**:

   ```bash> **Importante:** Em problemas m√©dicos, a acur√°cia por si s√≥ n√£o √© suficiente.

   git clone https://github.com/AlexandreJr16/Heart-Diseases.git> O custo de um **Falso Negativo** (paciente doente diagnosticado como saud√°vel) √© muito maior que o de um **Falso Positivo**.

   cd Heart-Diseases

   ```#### Matriz de Confus√£o



2. **Instale as depend√™ncias**:|                        | **Previsto: Saud√°vel (0)** | **Previsto: Doente (1)** |

   ```bash| ---------------------- | -------------------------- | ------------------------ |

   pip install -r requirements.txt| **Real: Saud√°vel (0)** | 93 (TN) ‚úÖ                 | 7 (FP) ‚ö†Ô∏è                |

   ```| **Real: Doente (1)**   | 8 (FN) ‚ùå                  | 97 (TP) ‚úÖ               |



3. **Execute o notebook**:#### M√©tricas Detalhadas por Classe

   ```bash

   jupyter notebook heart-diseases.ipynb| Classe           | Precision | Recall | F1-Score | Support |

   ```| ---------------- | --------- | ------ | -------- | ------- |

| **Saud√°vel (0)** | 92%       | 93%    | 93%      | 100     |

4. **Execute todas as c√©lulas** sequencialmente (Cell ‚Üí Run All) ou execute c√©lula por c√©lula para acompanhar a narrativa completa da an√°lise.| **Doente (1)**   | 93%       | 92%    | 93%      | 105     |



### Depend√™ncias Principais### üîç An√°lise Cr√≠tica



- TensorFlow 2.13.0+ (inclui Keras)#### ‚úÖ Pontos Fortes

- scikit-learn 1.3.0+

- pandas 2.0.0+1. **Recall (Sensibilidade) - Classe Doente: 92%**

- numpy 1.24.0+

- matplotlib 3.7.0+   - O modelo identificou corretamente **97 dos 105 pacientes doentes**

- seaborn 0.12.0+   - M√©trica crucial para aplica√ß√µes m√©dicas



---2. **Equil√≠brio entre Precision e Recall**



## üìö Refer√™ncias   - Ambas as m√©tricas > 92% para as duas classes

   - Modelo balanceado e confi√°vel

- UCI Machine Learning Repository: [Heart Disease Dataset](http://archive.ics.uci.edu/ml/datasets/Heart+Disease)

- Janosi, A., Steinbrunn, W., Pfisterer, M., & Detrano, R. (1988). Heart Disease Data Set. UCI Machine Learning Repository.3. **Baixa Taxa de Falsos Positivos**

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.   - Apenas 7 pacientes saud√°veis classificados como doentes

   - Evita exames desnecess√°rios

---

#### ‚ö†Ô∏è Pontos de Aten√ß√£o

## üë§ Autor

1. **Falsos Negativos: 8 casos**

**Alexandre Pereira de Souza Junior**     - Este √© o erro mais cr√≠tico

Projeto desenvolvido para a disciplina de Fundamentos de Intelig√™ncia Artificial   - 8 pacientes doentes foram classificados como saud√°veis

   - Em produ√ß√£o, seria necess√°rio um segundo n√≠vel de valida√ß√£o

---

### üìä Curvas de Aprendizado

**Licen√ßa**: MIT

**√öltima atualiza√ß√£o**: Novembro 2025O treinamento por 100 √©pocas mostrou:


- ‚úÖ Excelente converg√™ncia
- ‚úÖ Sem sinais de overfitting
- ‚úÖ Acur√°cia de valida√ß√£o acompanhando (e at√© superando) a de treino

---

## üöÄ Como Executar

### Pr√©-requisitos

- Python 3.8 ou superior
- pip instalado

### 1Ô∏è‚É£ Clone o Reposit√≥rio

```bash
git clone https://github.com/AlexandreJr16/Heart-Diseases.git
cd Heart-Diseases
`````

### 2Ô∏è‚É£ Instale as Depend√™ncias

```bash
pip install pandas numpy tensorflow scikit-learn matplotlib seaborn
```

Ou usando um arquivo `requirements.txt`:

```bash
pip install -r requirements.txt
```

### 3Ô∏è‚É£ Execute o Notebook

Abra o Jupyter Notebook em um ambiente de sua escolha:

**VS Code:**

```bash
code heart-diseases.ipynb
```

**Jupyter Lab:**

```bash
jupyter lab heart-diseases.ipynb
```

**Google Colab:**

- Fa√ßa upload do arquivo `.ipynb` e `heart.csv`

---

## üõ†Ô∏è Tecnologias Utilizadas

### Core Libraries

| Biblioteca       | Vers√£o | Prop√≥sito                    |
| ---------------- | ------ | ---------------------------- |
| **Python**       | 3.8+   | Linguagem base               |
| **TensorFlow**   | 2.0+   | Framework de Deep Learning   |
| **Keras**        | API    | Constru√ß√£o da Rede Neural    |
| **Scikit-learn** | Latest | Pr√©-processamento e m√©tricas |
| **Pandas**       | Latest | Manipula√ß√£o de dados         |
| **NumPy**        | Latest | Computa√ß√£o num√©rica          |
| **Matplotlib**   | Latest | Visualiza√ß√£o de dados        |
| **Seaborn**      | Latest | Visualiza√ß√£o estat√≠stica     |

---

## üí° Conclus√µes

### Principais Aprendizados

1. **Performance Excepcional**

   - O modelo de Rede Neural Artificial alcan√ßou **92.68% de acur√°cia**
   - Superou as expectativas iniciais do projeto

2. **Import√¢ncia da Normaliza√ß√£o**

   - Sem StandardScaler, caracter√≠sticas com escalas maiores (como `chol`) teriam dominado o aprendizado
   - Padroniza√ß√£o foi crucial para treinamento est√°vel e eficiente

3. **Preven√ß√£o de Data Leakage**

   - A metodologia rigorosa de fit/transform garantiu a integridade do modelo
   - Sem data leakage, os resultados refletem a verdadeira capacidade de generaliza√ß√£o

4. **M√©tricas Al√©m da Acur√°cia**
   - A an√°lise da matriz de confus√£o revelou insights cr√≠ticos
   - **Recall de 92%** para pacientes doentes √© o resultado mais importante

### Aplicabilidade Cl√≠nica

Este modelo poderia ser usado como:

- üè• **Ferramenta de triagem inicial** em unidades de sa√∫de
- üîç **Sistema de apoio √† decis√£o** para m√©dicos
- üìä **Identificador de pacientes de risco** para exames complementares

### Pr√≥ximos Passos

- [ ] Implementar valida√ß√£o cruzada (K-Fold)
- [ ] Testar arquiteturas mais profundas
- [ ] Aplicar t√©cnicas de ensemble (Random Forest, XGBoost)
- [ ] Analisar feature importance com SHAP values
- [ ] Desenvolver API REST para deploy do modelo

---

## üìù Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.
