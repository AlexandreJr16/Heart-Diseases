# Projeto 1: Classifica√ß√£o de Doen√ßas Card√≠acas - Fundamentos de IA

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://www.tensorflow.org/)
[![Keras](https://img.shields.io/badge/Keras-API-red.svg)](https://keras.io/)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3+-yellow.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Disciplina:** Fundamentos de Intelig√™ncia Artificial (FIA)  
> **Institui√ß√£o:** Universidade Federal do Amazonas (UFAM)  
> **Professor:** Edjard Mota  
> **Autores:** Alexandre Pereira de Souza Junior, Jo√£o Pedro Castro das Virgens, Leonardo Brand√£o do Amarante, Mateus Rodrigues Cavalcante, Vithor Junior da Encarna√ß√£o Vit√≥rio  
> **Per√≠odo:** 2¬∫ Semestre de 2025

---

## üìã Sum√°rio

- [Descri√ß√£o do Projeto](#-descri√ß√£o-do-projeto)
- [An√°lise do Dataset](#-an√°lise-do-dataset)
- [Metodologia](#-metodologia)
- [Resultados e An√°lise Cr√≠tica](#-resultados-e-an√°lise-cr√≠tica)
- [Conclus√µes](#-conclus√µes)
- [Como Executar](#-como-executar)
- [Tecnologias Utilizadas](#Ô∏è-tecnologias-utilizadas)
- [Refer√™ncias](#-refer√™ncias)

---

## üìñ Descri√ß√£o do Projeto

### Contexto e Objetivo

As **doen√ßas cardiovasculares** s√£o a principal causa de morte em todo o mundo. A detec√ß√£o precoce √©, portanto, um desafio cr√≠tico para a sa√∫de p√∫blica.

O objetivo deste projeto √© desenvolver um **classificador bin√°rio** utilizando Redes Neurais Artificiais (ANN) para prever a **presen√ßa (1)** ou **aus√™ncia (0)** de doen√ßa card√≠aca em pacientes, com base em 13 atributos cl√≠nicos.

### Especifica√ß√µes T√©cnicas

- **Tipo:** Classifica√ß√£o Bin√°ria Supervisionada
- **Modelo:** Rede Neural Feedforward com 2 camadas ocultas
- **Ativa√ß√µes:** ReLU (camadas ocultas), Sigmoid (sa√≠da)
- **Regulariza√ß√£o:** Dropout (35%) + L2 (0.01) + Early Stopping
- **M√©tricas:** Acur√°cia, Precis√£o, Recall e Matriz de Confus√£o

---

## üìä An√°lise do Dataset

### Fonte de Dados e Limpeza

Utilizamos o dataset cl√°ssico **"Heart Disease UCI (Cleveland)"**, que √© o benchmark hist√≥rico para este problema.

- **Fonte:** UCI Machine Learning Repository
- **URL:** http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data
- **Amostras Originais:** 303 pacientes
- **Limpeza:** O dataset original continha 6 linhas com valores nulos (marcados como `?`). Essas linhas foram removidas.
- **Amostras V√°lidas (Usadas):** 297 pacientes
- **Transforma√ß√£o do Alvo:** A vari√°vel `target` original (0-4) foi convertida para bin√°ria (0 = saud√°vel, 1 = doente).
- **Balanceamento:** O dataset resultante √© ligeiramente desbalanceado (160 Saud√°veis vs. 137 Doentes).

### Atributos Cl√≠nicos

Foram utilizadas **13 features** para a predi√ß√£o: `age`, `sex`, `cp` (tipo de dor no peito), `trestbps` (press√£o arterial), `chol` (colesterol), `fbs` (glicemia), `restecg` (eletrocardiograma), `thalach` (freq. card√≠aca m√°x.), `exang` (angina induzida), `oldpeak` (depress√£o ST), `slope` (inclina√ß√£o ST), `ca` (vasos principais), `thal` (talassemia).

---

## üß† Metodologia

O projeto seguiu um pipeline rigoroso de Data Science.

### Pipeline de Pr√©-processamento

1. **Carga e Limpeza:** Carregamento dos dados da UCI, tratamento de nulos (`?`) e transforma√ß√£o da `target` para bin√°ria.
2. **Divis√£o de Dados (Split):** Separa√ß√£o dos dados em 80% para treino (237 amostras) e 20% para teste (60 amostras). Foi usada a estratifica√ß√£o (`stratify=y`) para manter a propor√ß√£o de classes em ambos os conjuntos.
3. **Normaliza√ß√£o (Scaling):** Aplica√ß√£o do `StandardScaler` para normalizar os dados (m√©dia 0, desvio padr√£o 1).

### Arquitetura da Rede Neural

```
Input Layer (13 features)
‚Üì
Dense(16, ReLU) + L2 Regularization (0.01) + Dropout(0.35)
‚Üì
Dense(8, ReLU) + L2 Regularization (0.01) + Dropout(0.35)
‚Üì
Output(1, Sigmoid) ‚Üí Probabilidade [0, 1]
```

**Configura√ß√£o de Treinamento:**

- **Otimizador:** Adam
- **Fun√ß√£o de Perda:** `binary_crossentropy`
- **√âpocas:** 100 (com Early Stopping - patience 20)
- **Batch Size:** 10
- **Valida√ß√£o:** Conjunto de teste

### Import√¢ncia da Normaliza√ß√£o e Preven√ß√£o de Data Leakage

Esta foi a etapa t√©cnica **mais cr√≠tica**:

**Por que Normalizar?**

Redes Neurais s√£o sens√≠veis a escalas diferentes (ex: `chol` 126-564 vs `sex` 0-1). A normaliza√ß√£o garante uma converg√™ncia r√°pida e est√°vel.

**Preven√ß√£o de Data Leakage:**

Para evitar que o modelo "visse" os dados de teste, a ordem correta foi aplicada:

```python

# ‚úÖ CORRETO

scaler.fit(X_train) # Aprende apenas do treino
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

## ‚ùå ERRADO (causa data leakage)
scaler.fit(X) # Vaza informa√ß√£o do teste
```

Esta metodologia garante que os resultados de **83.3%** sejam uma estimativa honesta do desempenho do modelo em dados novos.

### Ajustes de Regulariza√ß√£o

O modelo passou por duas itera√ß√µes de ajuste:

**Vers√£o 1 (inicial):**

- Dropout: 25%
- L2: 0.001
- Problema: val_loss come√ßou a subir ap√≥s √©poca 10 (overfitting)

**Vers√£o 2 (final - implementada):**

- Dropout: 35%
- L2: 0.01
- Resultado: val_loss est√°vel, converg√™ncia r√°pida, overfitting eliminado

---

## üìà Resultados e An√°lise Cr√≠tica

### M√©tricas de Performance

O modelo foi avaliado no conjunto de teste de **60 amostras**.

| M√©trica               | Valor  |
| --------------------- | ------ |
| **Acur√°cia Global**   | 83.33% |
| **Precis√£o (Doente)** | 84.6%  |
| **Recall (Doente)**   | 78.6%  |
| **F1-Score (Doente)** | 0.81   |

### Matriz de Confus√£o (An√°lise Cr√≠tica)

A acur√°cia sozinha √© **insuficiente**. A matriz de confus√£o revela o custo dos erros.

```
Predito: Saud√°vel Predito: Doente
Real: Saud√°vel 26 4
Real: Doente 6 24
```

**An√°lise dos Erros:**

- **Falsos Positivos (FP):** 4 casos. Pacientes saud√°veis classificados como doentes. O custo √© moderado (exames adicionais, ansiedade).
- **Falsos Negativos (FN):** 6 casos. Pacientes doentes classificados como saud√°veis. **Este √© o erro cr√≠tico**, pois 6 pacientes n√£o receberiam tratamento.

**Conclus√£o M√©dica:** O Recall de 78.6% (o modelo encontrou 24 de 30 pacientes doentes) √© a m√©trica mais importante. Para uso cl√≠nico, este modelo serviria como **ferramenta de triagem**, mas o threshold de decis√£o (0.5) precisaria ser ajustado para reduzir os 6 Falsos Negativos, mesmo ao custo de aumentar os Falsos Positivos.

### An√°lise do Treinamento

O modelo foi treinado com Early Stopping (patience=20), monitorando val_loss. Os gr√°ficos de Acur√°cia/Perda mostraram:

- **Converg√™ncia R√°pida:** Com a regulariza√ß√£o ajustada (Dropout 35%, L2 0.01), o modelo convergiu em 5-10 √©pocas.
- **Estabilidade da Valida√ß√£o:** A perda de valida√ß√£o permaneceu est√°vel ao longo do treinamento, indicando boa generaliza√ß√£o.
- **Efeito do Dropout:** Durante o treinamento, val_loss < train_loss √© esperado, pois 35% dos neur√¥nios s√£o desativados no treino, mas todos est√£o ativos na valida√ß√£o.
- **Conclus√£o:** As t√©cnicas de regulariza√ß√£o (Dropout 35% + L2 0.01 + Early Stopping) foram eficazes em prevenir overfitting e permitir ao modelo atingir 83.3% de acur√°cia.

### An√°lise de Threshold

Al√©m do threshold padr√£o (0.5), foram testados valores de 0.3 a 0.7:

- **Threshold 0.3-0.4:** Recall ~88-95%, reduz Falsos Negativos para 2-4, mas aumenta Falsos Positivos para 6-8
- **Threshold 0.5 (atual):** Recall 78.6%, 6 FN, 4 FP - balanceamento padr√£o
- **Threshold 0.6-0.7:** Recall ~71%, aumenta FN para 7-10, reduz FP para 2-3

**Recomenda√ß√£o:** Para triagem m√©dica, threshold 0.35-0.40 √© prefer√≠vel, priorizando sensibilidade sobre especificidade.

---

## üí° Conclus√µes

### Efic√°cia do Modelo e Li√ß√µes Aprendidas

O modelo **cumpriu todos os requisitos t√©cnicos** do projeto, entregando um classificador funcional com uma acur√°cia realista de **83.33%**.

**Principais Aprendizados:**

1. **Ordem das Opera√ß√µes √© Cr√≠tica:** O pipeline correto (Split ‚Üí Fit ‚Üí Transform) √© fundamental para evitar data leakage e obter resultados v√°lidos.
2. **M√©tricas Contextuais > Acur√°cia:** Em medicina, o Recall e a an√°lise dos Falsos Negativos s√£o mais importantes que a acur√°cia total.
3. **Regulariza√ß√£o Forte para Datasets Pequenos:** Com apenas 297 amostras, foi necess√°rio usar Dropout 35% + L2 0.01 para prevenir overfitting.
4. **Early Stopping Economiza Recursos:** O treinamento parou automaticamente quando a valida√ß√£o estabilizou, evitando √©pocas desnecess√°rias.
5. **An√°lise de Threshold √© Fundamental:** O threshold padr√£o (0.5) pode n√£o ser ideal para aplica√ß√µes m√©dicas; threshold 0.35-0.40 seria mais apropriado para triagem.

### Aplicabilidade Cl√≠nica

Este modelo serve como uma excelente **prova de conceito**.

**Uso Recomendado:**

- Ferramenta de **triagem inicial** em unidades b√°sicas de sa√∫de
- Apoio √† decis√£o m√©dica (jamais como diagn√≥stico definitivo)
- Prioriza√ß√£o de pacientes para exames mais detalhados

**Limita√ß√µes:**

- Dataset pequeno (297 amostras) limita a generaliza√ß√£o
- Com threshold 0.5, h√° 6 Falsos Negativos (20% dos doentes n√£o detectados)
- Requer valida√ß√£o externa em outros datasets
- N√£o substitui avalia√ß√£o m√©dica profissional

**Melhorias Sugeridas:**

- Ajustar threshold para 0.35-0.40 (aumenta Recall para ~90%)
- Validar em dataset maior e mais diverso
- Implementar valida√ß√£o cruzada (k-fold)
- Explorar outras arquiteturas (CNN, RNN, ensemble methods)

---

## üöÄ Como Executar

### Pr√©-requisitos

- Python 3.8+
- Jupyter Notebook ou JupyterLab
- Git

### Instala√ß√£o

**1. Clone o reposit√≥rio:**

```bash
git clone https://github.com/AlexandreJr16/Heart-Diseases.git
cd Heart-Diseases
```

**2. Instale as depend√™ncias:**

```bash
pip install -r requirements.txt
```

Ou manualmente:

```bash
pip install pandas numpy tensorflow scikit-learn matplotlib seaborn
```

**3. Execute o notebook:**

```bash
jupyter notebook heart-diseases.ipynb
```

**4. Execute as c√©lulas sequencialmente** (Shift + Enter).

---

## üõ†Ô∏è Tecnologias Utilizadas

| Tecnologia       | Vers√£o  | Fun√ß√£o                       |
| ---------------- | ------- | ---------------------------- |
| **Python**       | 3.8+    | Linguagem de programa√ß√£o     |
| **TensorFlow**   | 2.13.0+ | Framework de Deep Learning   |
| **Keras**        | API     | Constru√ß√£o da Rede Neural    |
| **Scikit-learn** | 1.3.0+  | Pr√©-processamento e m√©tricas |
| **Pandas**       | 2.0.0+  | Manipula√ß√£o de dados         |
| **NumPy**        | 1.24.0+ | Computa√ß√£o num√©rica          |
| **Matplotlib**   | 3.7.0+  | Visualiza√ß√£o de dados        |
| **Seaborn**      | 0.12.0+ | Visualiza√ß√£o estat√≠stica     |

---

## üìö Refer√™ncias

- **Dataset:** Janosi, A., Steinbrunn, W., Pfisterer, M., & Detrano, R. (1988). Heart Disease Data Set. UCI Machine Learning Repository.
- **Teoria:** Goodfellow, I., Bengio, Y., & Courville, A. (2016). _Deep Learning_. MIT Press.
- **Implementa√ß√£o:** G√©ron, A. (2019). _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_. O'Reilly Media.

---

## üë• Autores

**Alexandre Pereira de Souza Junior**  
**Jo√£o Pedro Castro das Virgens**  
**Leonardo Brand√£o do Amarante**  
**Mateus Rodrigues Cavalcante**  
**Vithor Junior da Encarna√ß√£o Vit√≥rio**

**Institui√ß√£o:** Universidade Federal do Amazonas (UFAM)  
**Disciplina:** Fundamentos de Intelig√™ncia Artificial (FIA)  
**Professor:** Edjard Mota  
**Per√≠odo:** 2¬∫ Semestre de 2025

---

<div align="center">

**‚≠ê Se este projeto foi √∫til para seus estudos, considere dar uma estrela no reposit√≥rio!**

Desenvolvido com dedica√ß√£o para a disciplina de Fundamentos de IA üß†‚ù§Ô∏è

</div>
