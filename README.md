# Projeto 1: ClassificaÃ§Ã£o de DoenÃ§as CardÃ­acas - Fundamentos de IA# Projeto 1: ClassificaÃ§Ã£o de DoenÃ§as CardÃ­acas - Fundamentos de IA

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)

[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://www.tensorflow.org/)[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://www.tensorflow.org/)

[![Keras](https://img.shields.io/badge/Keras-API-red.svg)](https://keras.io/)[![Keras](https://img.shields.io/badge/Keras-API-red.svg)](https://keras.io/)

[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3+-yellow.svg)](https://scikit-learn.org/)[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3+-yellow.svg)](https://scikit-learn.org/)

[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Disciplina:** Fundamentos de InteligÃªncia Artificial (FIA) > **Disciplina:** Fundamentos de InteligÃªncia Artificial (FIA)

> **Autor:** Alexandre Pereira de Souza Junior, Leonardo BrandÃ£o, Vithor Vitorio. > **Autor:** Alexandre Pereira de Souza Junior, Leonardo BrandÃ£o, Vithor Vitorio.

---

## ğŸ“‹ Ãndice## ğŸ“‹ Ãndice

- [Contexto do Problema](#-contexto-do-problema)- [Contexto do Problema](#-contexto-do-problema)

- [Dataset: Origem, Estrutura e Limpeza](#-dataset-origem-estrutura-e-limpeza)- [Dataset: Origem, Estrutura e Limpeza](#-dataset-origem-estrutura-e-limpeza)

- [Metodologia](#ï¸-metodologia)- [Metodologia](#ï¸-metodologia)

- [Resultados e AnÃ¡lise CrÃ­tica](#-resultados-e-anÃ¡lise-crÃ­tica)- [Resultados e AnÃ¡lise CrÃ­tica](#-resultados-e-anÃ¡lise-crÃ­tica)

- [ConclusÃ£o](#-conclusÃ£o)- [ConclusÃ£o](#-conclusÃ£o)

- [InstruÃ§Ãµes de ExecuÃ§Ã£o](#-instruÃ§Ãµes-de-execuÃ§Ã£o)- [InstruÃ§Ãµes de ExecuÃ§Ã£o](#-instruÃ§Ãµes-de-execuÃ§Ã£o)

- [ReferÃªncias](#-referÃªncias)- [ReferÃªncias](#-referÃªncias)

---

## ğŸ“‹ Contexto do Problema## ğŸ“‹ Contexto do Problema

Este projeto acadÃªmico foi desenvolvido como parte da disciplina de Fundamentos de InteligÃªncia Artificial e tem como objetivo construir um **classificador binÃ¡rio** para prediÃ§Ã£o de doenÃ§as cardÃ­acas. O modelo desenvolvido classifica pacientes em duas categorias:Este projeto acadÃªmico foi desenvolvido como parte da disciplina de Fundamentos de InteligÃªncia Artificial e tem como objetivo construir um **classificador binÃ¡rio** para prediÃ§Ã£o de doenÃ§as cardÃ­acas. O modelo desenvolvido classifica pacientes em duas categorias:

- **0 (SaudÃ¡vel)**: AusÃªncia de doenÃ§a cardÃ­aca- **0:** AusÃªncia de doenÃ§a cardÃ­aca (SaudÃ¡vel)

- **1 (Doente)**: PresenÃ§a de doenÃ§a cardÃ­aca- **1:** PresenÃ§a de doenÃ§a cardÃ­aca (Doente)

A abordagem utiliza tÃ©cnicas de **Deep Learning** para analisar 13 atributos clÃ­nicos e fisiolÃ³gicos de pacientes, construindo uma Rede Neural Artificial (ANN) feedforward capaz de realizar prediÃ§Ãµes com base em dados histÃ³ricos.---

---## ğŸ› ï¸ Metodologia

## ğŸ”¬ Dataset: Origem, Estrutura e LimpezaO projeto foi estruturado em **cinco fases principais**, seguindo um pipeline rigoroso de Data Science para garantir a validade e a replicabilidade dos resultados.

### Fonte de Dados### Fase 1ï¸âƒ£: AnÃ¡lise ExploratÃ³ria de Dados (EDA)

O dataset utilizado Ã© o clÃ¡ssico **Cleveland Heart Disease Database** do repositÃ³rio UCI Machine Learning, acessÃ­vel via:Antes de qualquer modelagem, uma anÃ¡lise detalhada foi conduzida para entender a natureza dos dados:

````- **Balanceamento de Classes**: VerificaÃ§Ã£o da distribuiÃ§Ã£o entre pacientes saudÃ¡veis e doentes

http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data- **Matriz de CorrelaÃ§Ã£o**: IdentificaÃ§Ã£o de relaÃ§Ãµes lineares entre as features

```- **EstatÃ­sticas Descritivas**: CompreensÃ£o da distribuiÃ§Ã£o de cada atributo clÃ­nico



**Nota Importante sobre a Escolha do Dataset**: Durante a fase inicial do projeto, identificamos uma discrepÃ¢ncia entre o dataset sugerido no material de apoio (Kaggle, 1025 amostras) e o dataset utilizado no notebook de referÃªncia do professor. ApÃ³s anÃ¡lise crÃ­tica, confirmamos que o dataset correto para este projeto Ã© o **UCI Cleveland original (303 amostras)**, que representa o benchmark histÃ³rico para pesquisas em classificaÃ§Ã£o de doenÃ§as cardÃ­acas.### Fase 2ï¸âƒ£: PrÃ©-processamento e PrevenÃ§Ã£o de Data Leakage



### Estrutura do DatasetEsta foi a etapa tÃ©cnica **mais crÃ­tica** do projeto, onde seguimos rigorosamente as melhores prÃ¡ticas de Machine Learning.



- **Amostras Originais**: 303 pacientes#### Pipeline de PrÃ©-processamento

- **Atributos**: 13 features clÃ­nicas + 1 variÃ¡vel target

- **Features Incluem**: Idade, sexo, tipo de dor no peito (cp), pressÃ£o arterial em repouso (trestbps), colesterol sÃ©rico (chol), glicemia em jejum (fbs), resultados de ECG em repouso (restecg), frequÃªncia cardÃ­aca mÃ¡xima (thalach), angina induzida por exercÃ­cio (exang), depressÃ£o ST (oldpeak), inclinaÃ§Ã£o do segmento ST (slope), nÃºmero de vasos principais (ca), e talassemia (thal).1. **SeparaÃ§Ã£o de Features e Target**:

   ```python

#### Principais Features   X = data.drop('target', axis=1)  # 13 features

   y = data['target']               # variÃ¡vel binÃ¡ria

| Feature    | DescriÃ§Ã£o                              |   ```

| ---------- | -------------------------------------- |

| `age`      | Idade do paciente                      |2. **DivisÃ£o Estratificada Train/Test**:

| `sex`      | Sexo (1 = masculino, 0 = feminino)     |   ```python

| `cp`       | Tipo de dor no peito (0-3)             |   train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

| `trestbps` | PressÃ£o arterial em repouso (mm Hg)    |   ```

| `chol`     | Colesterol sÃ©rico (mg/dl)              |   - **Conjunto de Treino**: 237 amostras (80%)

| `fbs`      | Glicemia em jejum > 120 mg/dl          |   - **Conjunto de Teste**: 60 amostras (20%)

| `restecg`  | Resultados eletrocardiogrÃ¡ficos        |   - **EstratificaÃ§Ã£o**: MantÃ©m a proporÃ§Ã£o de classes em ambos os conjuntos

| `thalach`  | FrequÃªncia cardÃ­aca mÃ¡xima alcanÃ§ada   |

| `exang`    | Angina induzida por exercÃ­cio          |3. **NormalizaÃ§Ã£o (StandardScaler)** - **PONTO CRÃTICO**:

| `oldpeak`  | DepressÃ£o de ST induzida por exercÃ­cio |   ```python

| `slope`    | InclinaÃ§Ã£o do segmento ST de pico      |   scaler = StandardScaler()

| `ca`       | NÃºmero de vasos principais (0-3)       |   X_train_scaled = scaler.fit_transform(X_train)  # Fit APENAS no treino

| `thal`     | Talassemia (1-3)                       |   X_test_scaled = scaler.transform(X_test)        # Transform no teste

````

### Etapas de Limpeza

#### âš ï¸ ImportÃ¢ncia da NormalizaÃ§Ã£o dos Dados

1. **Tratamento de Valores Ausentes**: O dataset original continha valores nulos representados pelo caractere `'?'`. Esses valores foram identificados durante a carga dos dados utilizando o parÃ¢metro `na_values='?'` do pandas.

A normalizaÃ§Ã£o dos dados revelou-se **absolutamente essencial** para o sucesso do projeto:

2. **RemoÃ§Ã£o de Amostras Incompletas**: Aplicamos `dropna()` para remover todas as linhas com valores ausentes, resultando em **297 amostras vÃ¡lidas** para anÃ¡lise.

**Por que normalizar?**

3. **TransformaÃ§Ã£o da VariÃ¡vel Target**: A variÃ¡vel-alvo original era multi-classe (0, 1, 2, 3, 4), representando diferentes nÃ­veis de severidade da doenÃ§a. Convertemos para um problema binÃ¡rio aplicando a transformaÃ§Ã£o:- Redes Neurais sÃ£o altamente sensÃ­veis a caracterÃ­sticas em escalas diferentes

   ```python- Features como `chol`(126-564) dominariam features como`sex` (0-1) sem normalizaÃ§Ã£o

   target_binÃ¡rio = 1 if target_original > 0 else 0- A convergÃªncia do gradiente descendente Ã© muito mais eficiente com dados normalizados

   ```

   ```

**Por que esta ordem Ã© crucial?**

#### VariÃ¡vel-Alvo (Target)- Realizar o scaling **antes** da divisÃ£o train/test causaria **data leakage**

- InformaÃ§Ãµes estatÃ­sticas do conjunto de teste (mÃ©dia e desvio padrÃ£o) "vazariam" para o conjunto de treino

- **0:** AusÃªncia de doenÃ§a cardÃ­aca (SaudÃ¡vel)- O scaler deve aprender os parÃ¢metros **exclusivamente** dos dados de treino

- **1:** PresenÃ§a de doenÃ§a cardÃ­aca (Doente)- Esta prÃ¡tica simula o cenÃ¡rio real de produÃ§Ã£o, onde novos dados nunca foram vistos durante o treinamento

---### Fase 3ï¸âƒ£: ConstruÃ§Ã£o do Modelo (ANN)

## ğŸ› ï¸ MetodologiaDesenvolvemos uma Rede Neural Artificial feedforward com a seguinte arquitetura:

O projeto foi estruturado em **cinco fases principais**, seguindo um pipeline rigoroso de Data Science para garantir a validade e a replicabilidade dos resultados.```

Camada de Entrada: 13 neurÃ´nios (features)

### Fase 1ï¸âƒ£: AnÃ¡lise ExploratÃ³ria de Dados (EDA) â†“

Camada Oculta 1: 16 neurÃ´nios

Antes de qualquer modelagem, uma anÃ¡lise detalhada foi conduzida para entender a natureza dos dados: - AtivaÃ§Ã£o: ReLU

    - RegularizaÃ§Ã£o: L2 (lambda=0.001)

- **Balanceamento de Classes**: VerificaÃ§Ã£o da distribuiÃ§Ã£o entre pacientes saudÃ¡veis e doentes - Dropout: 25%

- **Matriz de CorrelaÃ§Ã£o**: IdentificaÃ§Ã£o de relaÃ§Ãµes lineares entre as features â†“

- **EstatÃ­sticas Descritivas**: CompreensÃ£o da distribuiÃ§Ã£o de cada atributo clÃ­nicoCamada Oculta 2: 8 neurÃ´nios

  - AtivaÃ§Ã£o: ReLU

### Fase 2ï¸âƒ£: PrÃ©-processamento e PrevenÃ§Ã£o de Data Leakage - RegularizaÃ§Ã£o: L2 (lambda=0.001)

    - Dropout: 25%

Esta foi a etapa tÃ©cnica **mais crÃ­tica** do projeto, onde seguimos rigorosamente as melhores prÃ¡ticas de Machine Learning. â†“

Camada de SaÃ­da: 1 neurÃ´nio

#### Pipeline de PrÃ©-processamento - AtivaÃ§Ã£o: Sigmoid (probabilidade de doenÃ§a)

````

1. **SeparaÃ§Ã£o de Features e Target**:

   ```python#### ConfiguraÃ§Ã£o de Treinamento

   X = data.drop('target', axis=1)  # 13 features

   y = data['target']               # variÃ¡vel binÃ¡ria| ParÃ¢metro          | Valor                       |

   ```| ------------------ | --------------------------- |

| **Optimizer**      | Adam                        |

2. **DivisÃ£o Estratificada Train/Test**:| **Loss Function**  | Binary Crossentropy         |

   ```python| **Epochs**         | 100                         |

   train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)| **Batch Size**     | 10                          |

   ```| **Regularization** | L2 (0.001) + Dropout (0.25) |

   - **Conjunto de Treino**: 237 amostras (80%)| **ValidaÃ§Ã£o**      | Conjunto de teste           |

   - **Conjunto de Teste**: 60 amostras (20%)

   - **EstratificaÃ§Ã£o**: MantÃ©m a proporÃ§Ã£o de classes em ambos os conjuntos#### EstratÃ©gia de RegularizaÃ§Ã£o



3. **NormalizaÃ§Ã£o (StandardScaler)** - **PONTO CRÃTICO**:- **L2 Regularization**: Penaliza pesos muito altos, promovendo uma distribuiÃ§Ã£o mais suave dos pesos

   ```python- **Dropout (25%)**: Durante o treino, desativa aleatoriamente 25% dos neurÃ´nios em cada camada oculta, forÃ§ando a rede a aprender representaÃ§Ãµes mais robustas e reduzindo a dependÃªncia de neurÃ´nios especÃ­ficos

   scaler = StandardScaler()

   X_train_scaled = scaler.fit_transform(X_train)  # Fit APENAS no treino### Fase 4ï¸âƒ£: Treinamento e AnÃ¡lise de Overfitting

   X_test_scaled = scaler.transform(X_test)        # Transform no teste

   ```O modelo foi treinado por 100 Ã©pocas com monitoramento contÃ­nuo das mÃ©tricas de treino e validaÃ§Ã£o. Os grÃ¡ficos de histÃ³rico revelaram um padrÃ£o clÃ¡ssico de **overfitting** apÃ³s aproximadamente 30-40 Ã©pocas:



#### âš ï¸ ImportÃ¢ncia da NormalizaÃ§Ã£o dos Dados- **AcurÃ¡cia de Treino**: Continuou aumentando atÃ© ~90%

- **AcurÃ¡cia de ValidaÃ§Ã£o**: Estagnou em ~83% e apresentou flutuaÃ§Ãµes

A normalizaÃ§Ã£o dos dados revelou-se **absolutamente essencial** para o sucesso do projeto:- **Perda de ValidaÃ§Ã£o**: ComeÃ§ou a aumentar enquanto a perda de treino diminuÃ­a



**Por que normalizar?****InterpretaÃ§Ã£o**: Este comportamento Ã© **esperado e normal** para um dataset pequeno (237 amostras de treino). As tÃ©cnicas de regularizaÃ§Ã£o (Dropout + L2) foram eficazes em limitar o overfitting, mas nÃ£o em eliminÃ¡-lo completamente.

- Redes Neurais sÃ£o altamente sensÃ­veis a caracterÃ­sticas em escalas diferentes

- Features como `chol` (126-564) dominariam features como `sex` (0-1) sem normalizaÃ§Ã£o### Fase 5ï¸âƒ£: AvaliaÃ§Ã£o Final e AnÃ¡lise CrÃ­tica

- A convergÃªncia do gradiente descendente Ã© muito mais eficiente com dados normalizados

A avaliaÃ§Ã£o final utilizou mÃºltiplas mÃ©tricas para fornecer uma visÃ£o completa da performance do modelo, com Ãªnfase especial nas mÃ©tricas mais relevantes para o contexto mÃ©dico.

**Por que esta ordem Ã© crucial?**

- Realizar o scaling **antes** da divisÃ£o train/test causaria **data leakage**A abordagem utiliza tÃ©cnicas de **Deep Learning** para analisar 13 atributos clÃ­nicos e fisiolÃ³gicos de pacientes, construindo uma Rede Neural Artificial (ANN) feedforward capaz de realizar prediÃ§Ãµes com base em dados histÃ³ricos.

- InformaÃ§Ãµes estatÃ­sticas do conjunto de teste (mÃ©dia e desvio padrÃ£o) "vazariam" para o conjunto de treino

- O scaler deve aprender os parÃ¢metros **exclusivamente** dos dados de treino---

- Esta prÃ¡tica simula o cenÃ¡rio real de produÃ§Ã£o, onde novos dados nunca foram vistos durante o treinamento

## ğŸ”¬ Dataset: Origem, Estrutura e Limpeza

### Fase 3ï¸âƒ£: ConstruÃ§Ã£o do Modelo (ANN)

### Fonte de Dados

Desenvolvemos uma Rede Neural Artificial feedforward com a seguinte arquitetura:

O dataset utilizado Ã© o clÃ¡ssico **Cleveland Heart Disease Database** do repositÃ³rio UCI Machine Learning, acessÃ­vel via:

````

Camada de Entrada: 13 neurÃ´nios (features)```

    â†“http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data

Camada Oculta 1: 16 neurÃ´nios```

    - AtivaÃ§Ã£o: ReLU

    - RegularizaÃ§Ã£o: L2 (lambda=0.001)**Nota Importante sobre a Escolha do Dataset**: Durante a fase inicial do projeto, identificamos uma discrepÃ¢ncia entre o dataset sugerido no material de apoio (Kaggle, 1025 amostras) e o dataset utilizado no notebook de referÃªncia do professor. ApÃ³s anÃ¡lise crÃ­tica, confirmamos que o dataset correto para este projeto Ã© o **UCI Cleveland original (303 amostras)**, que representa o benchmark histÃ³rico para pesquisas em classificaÃ§Ã£o de doenÃ§as cardÃ­acas.

    - Dropout: 25%

    â†“### Estrutura do Dataset

Camada Oculta 2: 8 neurÃ´nios

    - AtivaÃ§Ã£o: ReLU- **Amostras Originais**: 303 pacientes

    - RegularizaÃ§Ã£o: L2 (lambda=0.001)- **Atributos**: 13 features clÃ­nicas + 1 variÃ¡vel target

    - Dropout: 25%- **Features Incluem**: Idade, sexo, tipo de dor no peito (cp), pressÃ£o arterial em repouso (trestbps), colesterol sÃ©rico (chol), glicemia em jejum (fbs), resultados de ECG em repouso (restecg), frequÃªncia cardÃ­aca mÃ¡xima (thalach), angina induzida por exercÃ­cio (exang), depressÃ£o ST (oldpeak), inclinaÃ§Ã£o do segmento ST (slope), nÃºmero de vasos principais (ca), e talassemia (thal).

    â†“

Camada de SaÃ­da: 1 neurÃ´nio#### Principais Features

    - AtivaÃ§Ã£o: Sigmoid (probabilidade de doenÃ§a)

````| Feature    | DescriÃ§Ã£o                              |

| ---------- | -------------------------------------- |

#### ConfiguraÃ§Ã£o de Treinamento| `age`      | Idade do paciente                      |

| `sex`      | Sexo (1 = masculino, 0 = feminino)     |

| ParÃ¢metro          | Valor                       || `cp`       | Tipo de dor no peito (0-3)             |

| ------------------ | --------------------------- || `trestbps` | PressÃ£o arterial em repouso (mm Hg)    |

| **Optimizer**      | Adam                        || `chol`     | Colesterol sÃ©rico (mg/dl)              |

| **Loss Function**  | Binary Crossentropy         || `fbs`      | Glicemia em jejum > 120 mg/dl          |

| **Epochs**         | 100                         || `restecg`  | Resultados eletrocardiogrÃ¡ficos        |

| **Batch Size**     | 10                          || `thalach`  | FrequÃªncia cardÃ­aca mÃ¡xima alcanÃ§ada   |

| **Regularization** | L2 (0.001) + Dropout (0.25) || `exang`    | Angina induzida por exercÃ­cio          |

| **ValidaÃ§Ã£o**      | Conjunto de teste           || `oldpeak`  | DepressÃ£o de ST induzida por exercÃ­cio |

| `slope`    | InclinaÃ§Ã£o do segmento ST de pico      |

#### EstratÃ©gia de RegularizaÃ§Ã£o| `ca`       | NÃºmero de vasos principais (0-3)       |

| `thal`     | Talassemia (1-3)                       |

- **L2 Regularization**: Penaliza pesos muito altos, promovendo uma distribuiÃ§Ã£o mais suave dos pesos

- **Dropout (25%)**: Durante o treino, desativa aleatoriamente 25% dos neurÃ´nios em cada camada oculta, forÃ§ando a rede a aprender representaÃ§Ãµes mais robustas e reduzindo a dependÃªncia de neurÃ´nios especÃ­ficos### Etapas de Limpeza



### Fase 4ï¸âƒ£: Treinamento e AnÃ¡lise de Overfitting1. **Tratamento de Valores Ausentes**: O dataset original continha valores nulos representados pelo caractere `'?'`. Esses valores foram identificados durante a carga dos dados utilizando o parÃ¢metro `na_values='?'` do pandas.



O modelo foi treinado por 100 Ã©pocas com monitoramento contÃ­nuo das mÃ©tricas de treino e validaÃ§Ã£o. Os grÃ¡ficos de histÃ³rico revelaram um padrÃ£o clÃ¡ssico de **overfitting** apÃ³s aproximadamente 30-40 Ã©pocas:2. **RemoÃ§Ã£o de Amostras Incompletas**: Aplicamos `dropna()` para remover todas as linhas com valores ausentes, resultando em **297 amostras vÃ¡lidas** para anÃ¡lise.



- **AcurÃ¡cia de Treino**: Continuou aumentando atÃ© ~90%3. **TransformaÃ§Ã£o da VariÃ¡vel Target**: A variÃ¡vel-alvo original era multi-classe (0, 1, 2, 3, 4), representando diferentes nÃ­veis de severidade da doenÃ§a. Convertemos para um problema binÃ¡rio aplicando a transformaÃ§Ã£o:

- **AcurÃ¡cia de ValidaÃ§Ã£o**: Estagnou em ~83% e apresentou flutuaÃ§Ãµes   ```python

- **Perda de ValidaÃ§Ã£o**: ComeÃ§ou a aumentar enquanto a perda de treino diminuÃ­a   target_binÃ¡rio = 1 if target_original > 0 else 0

````

**InterpretaÃ§Ã£o**: Este comportamento Ã© **esperado e normal** para um dataset pequeno (237 amostras de treino). As tÃ©cnicas de regularizaÃ§Ã£o (Dropout + L2) foram eficazes em limitar o overfitting, mas nÃ£o em eliminÃ¡-lo completamente.

#### VariÃ¡vel-Alvo (Target)

### Fase 5ï¸âƒ£: AvaliaÃ§Ã£o Final e AnÃ¡lise CrÃ­tica

- **0:** AusÃªncia de doenÃ§a cardÃ­aca (SaudÃ¡vel)

A avaliaÃ§Ã£o final utilizou mÃºltiplas mÃ©tricas para fornecer uma visÃ£o completa da performance do modelo, com Ãªnfase especial nas mÃ©tricas mais relevantes para o contexto mÃ©dico.- **1:** PresenÃ§a de doenÃ§a cardÃ­aca (Doente)

---

## ğŸ“Š Resultados e AnÃ¡lise CrÃ­tica## ğŸ”¬ Metodologia

### MÃ©tricas de PerformanceO projeto foi estruturado em **quatro fases principais**, seguindo um pipeline rigoroso de Data Science.

| MÃ©trica | Valor |### Fase 1ï¸âƒ£: AnÃ¡lise ExploratÃ³ria de Dados (EDA)

|---------|-------|

| **AcurÃ¡cia Global** | 83.3% |Antes de qualquer modelagem, uma anÃ¡lise detalhada foi conduzida para entender a natureza dos dados.

| **PrecisÃ£o (Doente)** | 84.6% |

| **Recall (Doente)** | 78.6% |#### Principais Descobertas

| **F1-Score (Doente)** | 0.81 |

âœ… **Balanceamento Perfeito**

### Matriz de ConfusÃ£o

- 526 instÃ¢ncias da classe '1' (doente)

```- 499 instÃ¢ncias da classe '0' (saudÃ¡vel)

                 Predito: SaudÃ¡vel    Predito: Doente- ValidaÃ§Ã£o da **AcurÃ¡cia** como mÃ©trica confiÃ¡vel

Real: SaudÃ¡vel          26                   4

Real: Doente             6                  24âœ… **Qualidade dos Dados**

```

- Dataset completo, **sem valores nulos**

**InterpretaÃ§Ã£o Detalhada**:- NÃ£o exigiu etapas de imputation

- Pronto para modelagem apÃ³s scaling

1. **Verdadeiros Negativos (26)**: Pacientes saudÃ¡veis corretamente classificados como saudÃ¡veis

2. **Falsos Positivos (4)**: Pacientes saudÃ¡veis incorretamente classificados como doentes### Fase 2ï¸âƒ£: PrÃ©-Processamento e PrevenÃ§Ã£o de Data Leakage

3. **Falsos Negativos (6)**: Pacientes doentes incorretamente classificados como saudÃ¡veis âš ï¸

4. **Verdadeiros Positivos (24)**: Pacientes doentes corretamente classificados como doentesEsta foi a etapa tÃ©cnica mais crÃ­tica do projeto.

### ğŸ¥ AnÃ¡lise CrÃ­tica no Contexto MÃ©dico#### DivisÃ£o de Dados

#### ImportÃ¢ncia do Recall (78.6%)```python

Train: 80% | Test: 20%

Em aplicaÃ§Ãµes mÃ©dicas de diagnÃ³stico, o **Recall** (sensibilidade) Ã© frequentemente mais crÃ­tico que a precisÃ£o:Stratified Split (mantÃ©m proporÃ§Ã£o das classes)

````

- Um Recall de 78.6% significa que o modelo detectou corretamente **78.6% dos casos reais de doenÃ§a cardÃ­aca**

- Os **6 Falsos Negativos** representam o maior risco: pacientes doentes que nÃ£o receberiam o tratamento adequado se confiÃ¡ssemos apenas no modelo#### NormalizaÃ§Ã£o (StandardScaler)



#### Falsos Positivos vs. Falsos Negativos**Por que Ã© crucial?**

Redes Neurais sÃ£o altamente sensÃ­veis a caracterÃ­sticas em escalas diferentes:

- **Falsos Positivos (4)**: Pacientes saudÃ¡veis que seriam encaminhados para exames adicionais. Embora cause custos e ansiedade, Ã© o "erro menos perigoso"

- **Falsos Negativos (6)**: Pacientes doentes que receberiam alta mÃ©dica. Este Ã© o erro crÃ­tico que pode ter consequÃªncias fatais- `age`: 29-77

- `chol`: 126-564

#### ConclusÃ£o sobre Performance

**Metodologia Rigorosa para Prevenir Data Leakage:**

- Uma acurÃ¡cia de **83.3%** Ã© **realista e apropriada** para um dataset de 297 amostras

- O desempenho Ã© competitivo com estudos acadÃªmicos similares usando o mesmo dataset UCI```python

- Para uso clÃ­nico real, o modelo precisaria de:# âœ… CORRETO: Fit apenas no treino

  - Ajuste do threshold de decisÃ£o (reduzir de 0.5 para ~0.3) para aumentar o Recallscaler.fit(X_train)

  - ValidaÃ§Ã£o em datasets externos maioresX_train_scaled = scaler.transform(X_train)

  - IntegraÃ§Ã£o como ferramenta de triagem, nÃ£o diagnÃ³stico definitivoX_test_scaled = scaler.transform(X_test)



### ğŸ“ˆ AnÃ¡lise do Treinamento# âŒ ERRADO: Fit em todos os dados (causa data leakage)

scaler.fit(X)  # NÃƒO FAZER ISSO!

Os grÃ¡ficos de histÃ³rico de treinamento revelaram:```



- **ConvergÃªncia**: O modelo convergiu de forma estÃ¡vel nas primeiras 40 Ã©pocas### Fase 3ï¸âƒ£: Arquitetura e Treinamento do Modelo

- **Overfitting**: Detectado apÃ³s ~40 Ã©pocas, com divergÃªncia entre treino e validaÃ§Ã£o

- **EficÃ¡cia da RegularizaÃ§Ã£o**: Dropout e L2 limitaram o overfitting, mas nÃ£o o eliminaram completamente#### Arquitetura da Rede Neural



**Contexto**: Este padrÃ£o Ã© esperado e normal para datasets pequenos (237 amostras de treino).```

Input Layer (13 features)

---        â†“

Dense(16, ReLU) + L2 Regularization

## ğŸ¯ ConclusÃ£o        â†“

Dropout(0.25)

### EficÃ¡cia do Modelo        â†“

Dense(8, ReLU) + L2 Regularization

O modelo desenvolvido **atendeu plenamente aos requisitos do projeto**:        â†“

Dropout(0.25)

âœ… ConstruÃ§Ã£o de uma ANN feedforward com 2 camadas ocultas (ReLU) e regularizaÃ§Ã£o Dropout          â†“

âœ… Camada de saÃ­da com ativaÃ§Ã£o sigmoid para classificaÃ§Ã£o binÃ¡ria  Output(1, Sigmoid) â†’ Probabilidade [0, 1]

âœ… AvaliaÃ§Ã£o utilizando AcurÃ¡cia (83.3%), PrecisÃ£o (84.6%), Recall (78.6%) e Matriz de ConfusÃ£o  ```

âœ… Entrega de um classificador funcional com anÃ¡lise realista de desempenho

#### ConfiguraÃ§Ã£o de Treinamento

### ImportÃ¢ncia da NormalizaÃ§Ã£o dos Dados

| ParÃ¢metro          | Valor                       |

A normalizaÃ§Ã£o dos dados revelou-se **absolutamente essencial** para o sucesso do projeto:| ------------------ | --------------------------- |

| **Optimizer**      | Adam                        |

1. **ConvergÃªncia do Treinamento**: Sem normalizaÃ§Ã£o, as features com escalas maiores (ex: colesterol ~200-300) dominariam o gradiente, dificultando ou impedindo a convergÃªncia da rede neural.| **Loss Function**  | Binary Crossentropy         |

| **Epochs**         | 100                         |

2. **PrevenÃ§Ã£o de Data Leakage**: A aplicaÃ§Ã£o correta do StandardScaler (fit no treino, transform no teste) garantiu que o modelo nÃ£o tivesse acesso a informaÃ§Ãµes futuras, simulando adequadamente um cenÃ¡rio de produÃ§Ã£o.| **Batch Size**     | 10                          |

| **Regularization** | L2 (0.001) + Dropout (0.25) |

3. **Performance**: A normalizaÃ§Ã£o permitiu que todas as 13 features contribuÃ­ssem de forma balanceada para as prediÃ§Ãµes, resultando na acurÃ¡cia de 83.3%.

#### TÃ©cnicas de RegularizaÃ§Ã£o

### LiÃ§Ãµes Aprendidas

- **Dropout:** Previne overfitting desativando aleatoriamente 25% dos neurÃ´nios

- Datasets pequenos requerem tÃ©cnicas agressivas de regularizaÃ§Ã£o- **L2 Regularization:** Penaliza pesos grandes, promovendo generalizaÃ§Ã£o

- A ordem das operaÃ§Ãµes no pipeline de prÃ©-processamento Ã© crÃ­tica para a validade do modelo- **Validation Split:** Monitoramento contÃ­nuo da performance no teste

- MÃ©tricas contextuais (Recall em medicina) sÃ£o mais importantes que acurÃ¡cia global

- Overfitting Ã© um fenÃ´meno esperado e deve ser monitorado, nÃ£o necessariamente eliminado---



---## ğŸ“ˆ Resultados



## ğŸš€ InstruÃ§Ãµes de ExecuÃ§Ã£o### ğŸ¯ Performance Geral



### PrÃ©-requisitos```

AcurÃ¡cia no Conjunto de Teste: 92.68%

- Python 3.8+```

- Jupyter Notebook ou JupyterLab

Isso significa que o modelo classificou corretamente **quase 93 de cada 100 pacientes** no conjunto de teste.

### Passos para ExecuÃ§Ã£o

### ğŸ¥ AnÃ¡lise da Matriz de ConfusÃ£o

1. **Clone o repositÃ³rio**:

   ```bash> **Importante:** Em problemas mÃ©dicos, a acurÃ¡cia por si sÃ³ nÃ£o Ã© suficiente.

   git clone https://github.com/AlexandreJr16/Heart-Diseases.git> O custo de um **Falso Negativo** (paciente doente diagnosticado como saudÃ¡vel) Ã© muito maior que o de um **Falso Positivo**.

   cd Heart-Diseases

   ```#### Matriz de ConfusÃ£o



2. **Instale as dependÃªncias**:|                        | **Previsto: SaudÃ¡vel (0)** | **Previsto: Doente (1)** |

   ```bash| ---------------------- | -------------------------- | ------------------------ |

   pip install -r requirements.txt| **Real: SaudÃ¡vel (0)** | 93 (TN) âœ…                 | 7 (FP) âš ï¸                |

   ```| **Real: Doente (1)**   | 8 (FN) âŒ                  | 97 (TP) âœ…               |



3. **Execute o notebook**:#### MÃ©tricas Detalhadas por Classe

   ```bash

   jupyter notebook heart-diseases.ipynb| Classe           | Precision | Recall | F1-Score | Support |

   ```| ---------------- | --------- | ------ | -------- | ------- |

| **SaudÃ¡vel (0)** | 92%       | 93%    | 93%      | 100     |

4. **Execute todas as cÃ©lulas** sequencialmente (Cell â†’ Run All) ou execute cÃ©lula por cÃ©lula para acompanhar a narrativa completa da anÃ¡lise.| **Doente (1)**   | 93%       | 92%    | 93%      | 105     |



### DependÃªncias Principais### ğŸ” AnÃ¡lise CrÃ­tica



- TensorFlow 2.13.0+ (inclui Keras)#### âœ… Pontos Fortes

- scikit-learn 1.3.0+

- pandas 2.0.0+1. **Recall (Sensibilidade) - Classe Doente: 92%**

- numpy 1.24.0+

- matplotlib 3.7.0+   - O modelo identificou corretamente **97 dos 105 pacientes doentes**

- seaborn 0.12.0+   - MÃ©trica crucial para aplicaÃ§Ãµes mÃ©dicas



---2. **EquilÃ­brio entre Precision e Recall**



## ğŸ“š ReferÃªncias   - Ambas as mÃ©tricas > 92% para as duas classes

   - Modelo balanceado e confiÃ¡vel

- UCI Machine Learning Repository: [Heart Disease Dataset](http://archive.ics.uci.edu/ml/datasets/Heart+Disease)

- Janosi, A., Steinbrunn, W., Pfisterer, M., & Detrano, R. (1988). Heart Disease Data Set. UCI Machine Learning Repository.3. **Baixa Taxa de Falsos Positivos**

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.   - Apenas 7 pacientes saudÃ¡veis classificados como doentes

   - Evita exames desnecessÃ¡rios

---

#### âš ï¸ Pontos de AtenÃ§Ã£o

## ğŸ‘¤ Autor

1. **Falsos Negativos: 8 casos**

**Alexandre Pereira de Souza Junior**     - Este Ã© o erro mais crÃ­tico

Projeto desenvolvido para a disciplina de Fundamentos de InteligÃªncia Artificial   - 8 pacientes doentes foram classificados como saudÃ¡veis

   - Em produÃ§Ã£o, seria necessÃ¡rio um segundo nÃ­vel de validaÃ§Ã£o

---

### ğŸ“Š Curvas de Aprendizado

**LicenÃ§a**: MIT

**Ãšltima atualizaÃ§Ã£o**: Novembro 2025O treinamento por 100 Ã©pocas mostrou:


- âœ… Excelente convergÃªncia
- âœ… Sem sinais de overfitting
- âœ… AcurÃ¡cia de validaÃ§Ã£o acompanhando (e atÃ© superando) a de treino

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip instalado

### 1ï¸âƒ£ Clone o RepositÃ³rio

```bash
git clone https://github.com/AlexandreJr16/Heart-Diseases.git
cd Heart-Diseases
````

### 2ï¸âƒ£ Instale as DependÃªncias

```bash
pip install pandas numpy tensorflow scikit-learn matplotlib seaborn
```

Ou usando um arquivo `requirements.txt`:

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Execute o Notebook

Abra o Jupyter Notebook em um ambiente de sua escolha:

**VS Code:**

```bash
code heart-diseases.ipynb
```

**Jupyter Lab:**

```bash
jupyter lab heart-diseases.ipynb
```

**Google Colab:**

- FaÃ§a upload do arquivo `.ipynb` e `heart.csv`

---

## ğŸ› ï¸ Tecnologias Utilizadas

### Core Libraries

| Biblioteca       | VersÃ£o | PropÃ³sito                    |
| ---------------- | ------ | ---------------------------- |
| **Python**       | 3.8+   | Linguagem base               |
| **TensorFlow**   | 2.0+   | Framework de Deep Learning   |
| **Keras**        | API    | ConstruÃ§Ã£o da Rede Neural    |
| **Scikit-learn** | Latest | PrÃ©-processamento e mÃ©tricas |
| **Pandas**       | Latest | ManipulaÃ§Ã£o de dados         |
| **NumPy**        | Latest | ComputaÃ§Ã£o numÃ©rica          |
| **Matplotlib**   | Latest | VisualizaÃ§Ã£o de dados        |
| **Seaborn**      | Latest | VisualizaÃ§Ã£o estatÃ­stica     |

---

## ğŸ’¡ ConclusÃµes

### Principais Aprendizados

1. **Performance Excepcional**

   - O modelo de Rede Neural Artificial alcanÃ§ou **92.68% de acurÃ¡cia**
   - Superou as expectativas iniciais do projeto

2. **ImportÃ¢ncia da NormalizaÃ§Ã£o**

   - Sem StandardScaler, caracterÃ­sticas com escalas maiores (como `chol`) teriam dominado o aprendizado
   - PadronizaÃ§Ã£o foi crucial para treinamento estÃ¡vel e eficiente

3. **PrevenÃ§Ã£o de Data Leakage**

   - A metodologia rigorosa de fit/transform garantiu a integridade do modelo
   - Sem data leakage, os resultados refletem a verdadeira capacidade de generalizaÃ§Ã£o

4. **MÃ©tricas AlÃ©m da AcurÃ¡cia**
   - A anÃ¡lise da matriz de confusÃ£o revelou insights crÃ­ticos
   - **Recall de 92%** para pacientes doentes Ã© o resultado mais importante

### Aplicabilidade ClÃ­nica

Este modelo poderia ser usado como:

- ğŸ¥ **Ferramenta de triagem inicial** em unidades de saÃºde
- ğŸ” **Sistema de apoio Ã  decisÃ£o** para mÃ©dicos
- ğŸ“Š **Identificador de pacientes de risco** para exames complementares

### PrÃ³ximos Passos

- [ ] Implementar validaÃ§Ã£o cruzada (K-Fold)
- [ ] Testar arquiteturas mais profundas
- [ ] Aplicar tÃ©cnicas de ensemble (Random Forest, XGBoost)
- [ ] Analisar feature importance com SHAP values
- [ ] Desenvolver API REST para deploy do modelo

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ‘¤ Autor

**Alexandre Pereira de Souza Junior**

- GitHub: [@AlexandreJr16](https://github.com/AlexandreJr16)
- Projeto: [Heart-Diseases](https://github.com/AlexandreJr16/Heart-Diseases)

---

## ğŸ™ Agradecimentos

- Dataset fornecido pela comunidade UCI Machine Learning Repository
- Disponibilizado via Kaggle
- Disciplina de Fundamentos de InteligÃªncia Artificial (FIA)

---

<div align="center">

**â­ Se este projeto foi Ãºtil, considere dar uma estrela!**

Desenvolvido com â¤ï¸ e â˜• por Alexandre Jr.

</div>
